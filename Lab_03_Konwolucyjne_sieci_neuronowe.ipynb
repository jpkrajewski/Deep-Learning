{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "<font size=\"5\">\n",
    "\n",
    "Laboratorium z przedmiotu: \\\n",
    "**Głębokie uczenie i analiza obrazów**\n",
    "\n",
    "Ćwiczenie 3: \\\n",
    "**Konwolucyjne sieci neuronowe**\n",
    "\n",
    "</font>\n",
    "\n",
    "\\\n",
    "Marta Szarmach \\\n",
    "Zakład Telekomunikacji Morskiej \\\n",
    "Wydział Elektryczny \\\n",
    "Uniwersytet Morski w Gdyni\n",
    "\n",
    "09.2023\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "# 1. Wprowadzenie\n",
    "\n",
    "**Konwolucyjne sieci neuronowe** (ang. *convolutional neural networks*, CNN) to sieci, których działanie opiera się na konwolucji. W skrócie, sygnał dostarczony do sieci neuronowej (np. zdjęcie) analizowany jest fragment po fragmencie poprzez wykonanie konwolucji (wymnożenia i zsumowania) tegoż fragmentu z pewnym **filtrem** (ang. *kernel*). Zadaniem filtra jest (poprzez konwolucję) rozpoznanie w analizowanym sygnale pewnych cech (np. krawędzi), a na późniejszych etapie nawet pewnych obiektów. To właśnie na zawartość filtra składają się parametry sieci konwolucyjnej, wyznaczane w ramach jej treningu. \n",
    "\n",
    "Z racji swojej budowy i działania, konwolucyjne sieci neuronowe znalazły szerokie zastosowanie w analizie obrazów. Obrazy są najczęściej przedstawiane w formie 3-kanałowych macierzy (RGB), a następnie poddawane są konwolucji z filtrami, na którą wzór można zapisać tak:\n",
    "\\begin{equation*}\n",
    "    (A * H)[m,n] = \\sum_j \\sum_k H[j,k] \\cdot A[m-j,n-k]\n",
    "\\end{equation*}\n",
    "Każdy filtr ma za zadanie wykryć pewną konkretną cechę/zawartość analizowanego fragmentu obrazu. Zaczyna się zazwyczaj od odnajdywania prostych elementów, takich, jak krawędzie, a następnie, na kolejnych warstwach, sieć jest w stanie wykrywać coraz bardziej złożone kształty i obiekty. Zazwyczaj z każdą kolejną warstwą konwolucyjną zmniejsza się szerokość i wysokość obrazka, a zwiększa się ilość kanałów sygnału (tj. wykrywa się więcej kształtów - każdy kanał filtra odpowiada za odnajdywanie innych rodzajów kształtów, a tensor otrzymywany na wyjściu warstwy konwolucyjnej ma tyle kanałów, ile filtr na tej warstwie).\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/Argenni/GUiAO_lab/main/rys/04_cnn.png'/>\n",
    "\n",
    "<font size=\"1\">Grafika: developersbreach.com</font>\n",
    "</div>\n",
    "\n",
    "Typowa budowa sieci konwolucyjnej przedstawiona jest na powyższym rysunku. Zazwyczaj sieci te buduje się z kilku występującycj po sobie bloków, złożonych z warstwy konwolucyjnej (wykonującej właściwą konwolucję), warstwy aktywacyjnej (np. ReLU) oraz innych, takich jak *dropout* czy *BatchNorm*. Na końcu sieci znajduje się najczęściej warstwa Flatten, która sprowadza dane dlań wejściowe do postaci 1-wymiarowego tensora, a za nią dane te przekształcane są przez jedną bądź kilka warstw liniowych. Na końcu sieci występuje warstwa przeprowadzająca ostateczną predykcję - w zależności od rozwiązywanego problemu, może to być Sigmoid, Softmax, itp.\n",
    "\n",
    "Pomiędzy blokami konwolucyjnymi możemy użyć także dodatkowej warstwy, zwanej *pooling layer*, która ma na celu zmiejszenie wymiaru ,,obrazu'' przekazywanego do następnej warstwy. Mamy fo wyboru:\n",
    "* *max pooling* - grupa pikseli zastępowana jest jednym, o wartości największej z grupy,\n",
    "* *average pooling* - grupa pikseli zastępowana jest jednym, o wartości średniej całej grupy.\n",
    "\n",
    "Hiperparametrami regulującymi działanie konwolucyjnych sieci neuronowych, które nie występowały w ,,zwykłych'' sieciach neuronowych (opartych na warstwach liniowych), są:\n",
    "* *kernel_size* - wielkość filtra,\n",
    "* *padding* - określa, jak „szeroka” ma być dodana (na dowolnej warstwie) do obrazu ramka z zer, co ma przeciwdziałać nadmiernemu zmiejszaniu się wymiarów obrazu wraz z kolejnymi konwolucjami, a także umożliwić dokładniejszą analizę brzegów obrazu,\n",
    "* *stride* - określa, za ile pikseli filtr wykona następną konwolucję.\n",
    "\n",
    "\n",
    "\n",
    "# 2. Cel ćwiczenia\n",
    "\n",
    "**Celem niniejszego ćwiczenia** jest zapoznanie się z budową i działaniem konwolucyjnych sieci neuronowych poprzez:\n",
    "* implementacji architektury pewnej konwolucyjnej sieci neuronowej o niewielkiej ilości warstw z wykorzystaniem biblioteki PyTorch i języka programowania Python,\n",
    "* skorzystanie z implementacji gotowej sieci konwolucyjnej, realizującej klasyfikację obrazów - AlexNet.\n",
    "\n",
    "\n",
    "# 3. Stanowisko laboratoryjne\n",
    "\n",
    "Do wykonania niniejszego ćwiczenia niezbędne jest stanowisko laboratoryjne, składające się z komputera klasy PC z zainstalowanym oprogramowaniem:\n",
    "* językiem programowania Python (w wersji 3.8),\n",
    "* IDE obsługującym pliki Jupyter Notebook (np. Visual Studio Code z rozszerzeniem ipykernel).\n",
    "\n",
    "\n",
    "# 4. Przebieg ćwiczenia\n",
    "## 4.1. Implementacja konwolucyjnej sieci neuronowej z wykorzystaniem biblioteki PyTorch\n",
    "\n",
    "Na początku wykonaj poniższy fragment kodu, aby zaimportować biblioteki niezbędne do wykonania poniższego ćwiczenia:\n",
    "* **PyTorch** - biblioteka wspomagająca budowanie architektur sieci neuronowych, posiadająca wbudowane moduły odpowiadające różnym warstwom sieci neuronowych, automatyczne obliczanie gradientów (*autograd*) niezbędne do przeprowadzenia treningu sieci neuronowych,\n",
    "* **NumPy** - biblioteka umożliwiająca wykonywanie wysoko zoptymalizowanych obliczeń matematycznych na objektach typu *numpy array* (wielowymiarowych tablic),\n",
    "* **Matplotlib** - biblioteka wspomagająca wizualizację pracy czy analizę danych poprzez wyświetlanie wykresów,\n",
    "* **Scikit-learn** - biblioteka zawierająca gotowe implementacje wielu algorytmów klasycznego uczenia maszynowego, a także zbiory danych czy metryki; tutaj skorzystamy ze zbioru danych `digits` (uproszczonej wersji zbioru MNIST) - `datasets.load_digits` oraz metody `model_selection.train_test_split` służącej do podziału danych na zestaw treningowy i testowy,\n",
    "* **Optuna** - biblioteka zawierająca narzędzia automatyzujące optymalizację danej funkcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/jakub/venv_advanced/lib/python3.9/site-packages (from torch==2.0.1) (4.8.0)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.0.0\n",
      "  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jinja2\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/jakub/venv_advanced/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (58.1.0)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.41.3-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cmake\n",
      "  Downloading cmake-3.27.7-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lit\n",
      "  Downloading lit-17.0.4.tar.gz (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.1/153.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: lit\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-17.0.4-py3-none-any.whl size=93257 sha256=120de6ee212d87357640cd5761669ad51e783d48795c58cff887eb7b67500a5c\n",
      "  Stored in directory: /home/jakub/.cache/pip/wheels/65/b5/5f/393c25945f561fcc619d4ce4ca365020675dbddb0c92cb5ef6\n",
      "Successfully built lit\n",
      "Installing collected packages: mpmath, lit, cmake, wheel, sympy, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, networkx, MarkupSafe, filelock, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, jinja2, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
      "Successfully installed MarkupSafe-2.1.3 cmake-3.27.7 filelock-3.13.1 jinja2-3.1.2 lit-17.0.4 mpmath-1.3.0 networkx-3.2.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 sympy-1.12 torch-2.0.1 triton-2.0.0 wheel-0.41.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: numpy==1.22.3 in /home/jakub/venv_advanced/lib/python3.9/site-packages (1.22.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scikit-learn==0.24.2 in /home/jakub/venv_advanced/lib/python3.9/site-packages (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/jakub/venv_advanced/lib/python3.9/site-packages (from scikit-learn==0.24.2) (1.3.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/jakub/venv_advanced/lib/python3.9/site-packages (from scikit-learn==0.24.2) (1.11.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jakub/venv_advanced/lib/python3.9/site-packages (from scikit-learn==0.24.2) (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/jakub/venv_advanced/lib/python3.9/site-packages (from scikit-learn==0.24.2) (1.22.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib==3.4.2 in /home/jakub/venv_advanced/lib/python3.9/site-packages (3.4.2)\n",
      "Requirement already satisfied: numpy>=1.16 in /home/jakub/venv_advanced/lib/python3.9/site-packages (from matplotlib==3.4.2) (1.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/jakub/venv_advanced/lib/python3.9/site-packages (from matplotlib==3.4.2) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/jakub/venv_advanced/lib/python3.9/site-packages (from matplotlib==3.4.2) (3.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jakub/venv_advanced/lib/python3.9/site-packages (from matplotlib==3.4.2) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jakub/venv_advanced/lib/python3.9/site-packages (from matplotlib==3.4.2) (10.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jakub/venv_advanced/lib/python3.9/site-packages (from matplotlib==3.4.2) (0.12.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/jakub/venv_advanced/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib==3.4.2) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting optuna\n",
      "  Downloading optuna-3.4.0-py3-none-any.whl (409 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting alembic>=1.5.0\n",
      "  Downloading alembic-1.12.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/jakub/venv_advanced/lib/python3.9/site-packages (from optuna) (23.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/jakub/venv_advanced/lib/python3.9/site-packages (from optuna) (2.0.22)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: numpy in /home/jakub/venv_advanced/lib/python3.9/site-packages (from optuna) (1.22.3)\n",
      "Collecting PyYAML\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /home/jakub/venv_advanced/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (4.8.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/jakub/venv_advanced/lib/python3.9/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/jakub/venv_advanced/lib/python3.9/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Installing collected packages: tqdm, PyYAML, Mako, colorlog, alembic, optuna\n",
      "Successfully installed Mako-1.2.4 PyYAML-6.0.1 alembic-1.12.1 colorlog-6.7.0 optuna-3.4.0 tqdm-4.66.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakub/venv_advanced/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f26e3701890>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! python -m pip install torch==2.0.1\n",
    "! python -m pip install numpy==1.22.3\n",
    "! python -m pip install scikit-learn==0.24.2\n",
    "! python -m pip install matplotlib==3.4.2\n",
    "! python -m pip install optuna\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "# (dla zachowania powtarzalności wyników)\n",
    "np.random.seed(10) \n",
    "torch.manual_seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie i przygotowanie danych\n",
    "\n",
    "Na początku przygotujmy dane, na których będziemy dziś pracować. Tym razem korzystać będziemy ze zbioru `digits`, zawierającego *num_samples* = 1797 obrazków o rozmiarze 8x8, przedstawiających odręcznie pisane cyfry. Uruchom kod z poniższej komórki, aby:\n",
    "* wczytać oryginalne dane (`digits`) do zmiennej $X$ i ich etykiety do zmiennej $y$,\n",
    "* obliczyć (z wykorzystaniem metody `numpy.unique`) w automatyczny sposób ilość klas występujących w naszym zbiorze danych (tj. ilość unikalnych wartości w etykietach) - wiemy, że powinno ich być 10, tyle, ile cyfr,\n",
    "* z pomocą `train_test_split` wydzielić 70% obrazków jako zestaw treningowy $Xtrain$, a pozostałą część danych po równo podzielić na zestaw walidacyjny $Xval$ i testowy $Xtest$ (po 15%),\n",
    "* przygotować etykiety tak, aby współpracowały z funkcją kosztu `CrossEntropyLoss`, którą zastosujemy przy treningu naszej sieci - odpowiedź od każdego neuronu zbierana będzie w osobnej kolumnie tablicy, dlatego nasze etykiety w formacie (*num_samples*,), zawierające wartości 0,1,...9 przekształcimy za pomocą one-hot-encodingu do postaci (*num_samples*, *num_classes*), np. 2 -> [0,0,1]\n",
    "* ostatecznie, dane i przekształcone etykiety, które będą przekazywane sieci neuronowej, przekształcić do formatu `torch.tensor`, aby były zrozumiałe dla PyTorcha; jednocześnie wyodrębniając w danych jako drugi wymiar ilość kanałów (w tym przypadku jest to 1): nasze dane wejściowe mają teraz kształt (*num_samples*, *num_channels*, *sample_size*, *sample_size*), gdzie *num_channels* = 1 (dla obrazów RGB byłoby to 3), *sample_size*=8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Inicjalizacja ----------------------------\n",
    "# Wczytanie danych\n",
    "digits = load_digits()\n",
    "X = digits.images\n",
    "y = digits.target\n",
    "num_classes = (np.unique(y)).shape[0]\n",
    "# Podziel dane na zestaw treningowy (70%), walidacyjny (15%) i testowy (15%) z wykorzystaniem metody train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,train_size=0.6)\n",
    "Xval, Xtest, yval, ytest = train_test_split(Xtest,ytest,train_size=0.5)\n",
    "# Dokonaj one-hot-encodingu etykiet z zestawu treningowego i walidacyjnego\n",
    "ytrain_ohe = np.identity(num_classes)[ytrain]\n",
    "yval_ohe = np.identity(num_classes)[yval]\n",
    "# Przekonwertuj dane wejściowe na tensory, by mogłby być obsługiwane przez PyTorch\n",
    "# i jednocześnie wydziel wymiar 1 jako ilość kanałów\n",
    "Xtrain = torch.tensor(Xtrain.reshape(-1, 1, Xtrain.shape[1], Xtrain.shape[2]))\n",
    "ytrain_ohe = torch.tensor(ytrain_ohe) \n",
    "Xval = torch.tensor(Xval.reshape(-1, 1, Xval.shape[1], Xval.shape[2])) \n",
    "yval_ohe = torch.tensor(yval_ohe)\n",
    "Xtest = torch.tensor(Xtest.reshape(-1, 1, Xtest.shape[1], Xtest.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Określenie struktury naszej sieci neuronowej\n",
    "\n",
    "W kolejnym kroku zdefiniujemy strukturę naszej konwolucyjnej  sieci neuronowej, korzystając z klas dostępnych w bibliotece PyTorch! Tak samo, jak ostatnio, zrobimy to w naszej własnej klasie - nazwijmy ją `ConvNet` - która musi dziedziczyć z klasy `torch.nn.Module`, w której umieścimy dwie metody:\n",
    "* metodę-konstruktor `__init__()` - opisującą budowę sieci; skorzystamy tu ze znanych już wcześniej warstw `torch.nn.Linear`, `torch.nn.ReLU`, `torch.nn.Dropout`, `torch.nn.Softmax` czy `torch.nn.Sequential`, ale użyjemy także kilku nowych, charakterystycznych dla konwolucyjnych sieci neuronowych:\n",
    "    * `torch.nn.Conv2d` - ([TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)) - realizująca właściwą konwolucję pomiędzy filtrami a fragmentami obrazów; wymaga takich argumentów, jak: ilość kanałów wejściowych/wyjściowych, wielkość filtra, *padding*, *stride*,\n",
    "    * `torch.nn.BatchNorm` - ([TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)) i ([TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html)) - realizująca normalizację wsadową, zarówno na obrazach (2d), jak i na 1-wymiarowych tensorach (1d),\n",
    "    * `torch.nn.Flatten` - ([TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html)) - realizująca ,,wypłaszczenie'' wejściowego sygnału 2d do postaci 1-wymiarowego tensora.\n",
    "* metodę `forward()` - w której określamy przepływ danych pomiędzy warstwami.\n",
    "\n",
    "Uzupełnij zatem poniższy kod! Oto założenia:\n",
    "* Niech nasza sieć neuronowa składa się z następujących warstw:\n",
    "\n",
    "2 x (`Conv2d` -> `BatchNorm2d` -> `Dropout` -> `ReLU`) -> `Flatten` -> `Linear` -> `BatchNorm1d` -> `Dropout` -> `Softmax`.\n",
    "* Podczas pierwszej konwolucji, niech wyznaczonych zostanie 16 kanałów, a po drugiej - 32 (ilość kanałów przechowywana jest w tablicy `num_conv_channels`).\n",
    "* Prawdopodobieństwo odrzucenia neuronu przez `dropout` niech wynosi 0,25.\n",
    "\n",
    "<font size=\"2\">Wskazówki:\n",
    "* Po każdej konwolucji, wymiary obrazu (szerokość i długość) zmieniają się zgodnie z poniższym wzorem:\n",
    "\\begin{equation*}\n",
    "    sample\\_size_{\\textrm{new}} = \\frac{sample\\_size_{\\textrm{original}} + 2 \\cdot padding - kernel\\_size}{stride} + 1 \n",
    "\\end{equation*}\n",
    "* Zastanów się, jak długi tensor zwróci nam warstwa `Flatten` (będzie Ci to potrzebne do właściwej inicjalizacji warstwy `Linear`) - do policzenia tego, na pewno będziesz potrzebować wymiaru obrazka po ostatniej konwolucji, a także ilości kanałów po tejże konwolucji!\n",
    "* `BatchNorm2d` jako argument  `num_features` wymaga ilości kanałów w analizowanych przezeń danych, natomiast `BatchNorm1d` - ilość neuronów z ostatniej warstwy `Linear`.\n",
    "* Wszystkie niezbędne dane przekazywać będziemy konstruktorowi jako argumenty.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Model konwolucyjnej sieci neuronowej:\n",
    "    (Conv -> BatchNorm -> Dropout -> ReLU) -> (Conv -> BatchNorm -> Dropout -> ReLU) -> (Flatten -> Linear -> BatchNorm -> Dropout -> Softmax)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_channels, sample_size, output_layer_size, kernel_size, padding, stride):\n",
    "        \"\"\"\n",
    "        Definiuje budowę sieci. Argumenty: \\n\n",
    "        - input_channels - ilość kanałów w wejściowych obrazkach (skalar, int), \\n\n",
    "        - sample_size - długość/szerokość wejściowego obrazka (skalar, int), \\n\n",
    "        - output_layer_size - ilość neuronów na ostatniej warstwie (skalar, int), \\n\n",
    "        - kernel_size - wielkość filtra do konwolucji (skalar, int), \\n\n",
    "        - padding - ,,grubość'' ramki z zer dodowananej do obrazka (skalar, int), \\n\n",
    "        - stride - co ile pikseli obrazka wykonywana jest konwolucja (skalar, int).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        num_conv_channels = [16, 32] # Do dowolnej modyfikacji - ilość kanałów po kolejnych konwolucjach\n",
    "        # ---------------------- UZUPEŁNIJ KOD -----------------------------------\n",
    "        # Oblicz rozmiary obrazków po pierwszej konwolucji\n",
    "        size1 = (sample_size + 2 * padding - kernel_size) / stride + 1\n",
    "        # Oblicz rozmiary obrazków po drugiej konwolucji\n",
    "        size2 = (size1 + 2 * padding - kernel_size) / stride + 1\n",
    "        # Zacznij definiować budowę sieci:\n",
    "        self.first_layer = torch.nn.Sequential(\n",
    "            # Warstwa konwolucyjna\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=input_channels,\n",
    "                out_channels=num_conv_channels[0],\n",
    "                kernel_size=kernel_size,\n",
    "                padding=padding,\n",
    "                stride=stride\n",
    "            ),\n",
    "            # BatchNorm2d\n",
    "            torch.nn.BatchNorm2d(\n",
    "                num_features=num_conv_channels[0]\n",
    "            ),\n",
    "            # Dropout (niech neuron zostanie usunięty z prawdopodobieństwem 0.25)\n",
    "            torch.nn.Dropout(0.25),\n",
    "            # Funkcja aktywacji ReLU\n",
    "            torch.nn.ReLU()\n",
    "            )\n",
    "        self.second_layer = torch.nn.Sequential(\n",
    "            # Warstwa konwolucyjna\n",
    "            torch.nn.Conv2d(\n",
    "                \n",
    "            ),\n",
    "            # BatchNorm2d\n",
    "            torch.nn.BatchNorm2d(),\n",
    "            # Dropout (niech neuron zostanie usunięty z prawdopodobieństwem 0.25)\n",
    "            torch.nn.Dropout(0.25),\n",
    "            # Funkcja aktywacji ReLU\n",
    "            torch.nn.ReLU()\n",
    "            )\n",
    "        self.third_layer = torch.nn.Sequential(\n",
    "            # Flatten\n",
    "            torch.nn.Flatten(),\n",
    "            # Linear\n",
    "            torch.nn.Linear(),\n",
    "            # BatchNorm1d\n",
    "            torch.nn.BatchNorm1d(),\n",
    "            # Dropout\n",
    "            torch.nn.Dropout(),\n",
    "            # Softmax\n",
    "           torch.nn.Softmax()\n",
    "        )\n",
    "        # ---------------------------------------------------------------------\n",
    "\n",
    "    def forward(self, X):\n",
    "            \"\"\" \n",
    "            Definiuje przepływ danych w sieci. \\n\n",
    "            Argument: X - dane wejściowe, obrazki w postaci torch.tensor, shape=(num_samples, input_channels, sample_size, sample_size). \\n\n",
    "            Zwraca: X - odpowiedź sieci w postaci prawdopodobieństw, torch.tensor, shape=(sum_samples, num_classes).\n",
    "            \"\"\"\n",
    "            # ------------------- UZUPEŁNIJ KOD ----------------\n",
    "            X = 0\n",
    "            # --------------------------------------------------\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Model konwolucyjnej sieci neuronowej:\n",
    "    (Conv -> BatchNorm -> Dropout -> ReLU) -> (Conv -> BatchNorm -> Dropout -> ReLU) -> (Flatten -> Linear -> BatchNorm -> Dropout -> Softmax)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, sample_size, output_layer_size, kernel_size, padding, stride):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Definiuje budowę sieci. Argumenty: \\n\n",
    "        - input_channels - ilość kanałów w wejściowych obrazkach (skalar, int), \\n\n",
    "        - sample_size - długość/szerokość wejściowego obrazka (skalar, int), \\n\n",
    "        - output_layer_size - ilość neuronów na ostatniej warstwie (skalar, int), \\n\n",
    "        - kernel_size - wielkość filtra do konwolucji (skalar, int), \\n\n",
    "        - padding - ,,grubość'' ramki z zer dodowananej do obrazka (skalar, int), \\n\n",
    "        - stride - co ile pikseli obrazka wykonywana jest konwolucja (skalar, int).\n",
    "        \"\"\"\n",
    "        num_conv_channels = [16, 32]\n",
    "        size1 = (sample_size + 2 * padding - kernel_size) // stride + 1\n",
    "        size2 = (size1 + 2 * padding - kernel_size) // stride + 1\n",
    "        \n",
    "        self.first_layer = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=input_channels,\n",
    "                out_channels=num_conv_channels[0],\n",
    "                kernel_size=kernel_size,\n",
    "                padding=padding,\n",
    "                stride=stride\n",
    "            ),\n",
    "            torch.nn.BatchNorm2d(num_conv_channels[0]),\n",
    "            torch.nn.Dropout(0.25),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.second_layer = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=num_conv_channels[0],  # Update the number of input channels\n",
    "                out_channels=num_conv_channels[1],\n",
    "                kernel_size=kernel_size,\n",
    "                padding=padding,\n",
    "                stride=stride\n",
    "            ),\n",
    "            torch.nn.BatchNorm2d(num_conv_channels[1]),\n",
    "            torch.nn.Dropout(0.25),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.third_layer = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(num_conv_channels[1] * size2 * size2, output_layer_size),  # Update the input features\n",
    "            torch.nn.BatchNorm1d(output_layer_size),\n",
    "            torch.nn.Dropout(0.25),  # Specify the dropout probability\n",
    "            torch.nn.Softmax(dim=1)  # Specify the dimension for softmax\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\" \n",
    "            Definiuje przepływ danych w sieci. \\n\n",
    "            Argument: X - dane wejściowe, obrazki w postaci torch.tensor, shape=(num_samples, input_channels, sample_size, sample_size). \\n\n",
    "            Zwraca: X - odpowiedź sieci w postaci prawdopodobieństw, torch.tensor, shape=(sum_samples, num_classes).\n",
    "        \"\"\"\n",
    "        # ------------------- UZUPEŁNIJ KOD ----------------\n",
    "        X = self.first_layer(X)\n",
    "        X = self.second_layer(X)\n",
    "        X = self.third_layer(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spróbujmy utworzyć obiekt stworzonej przez nas klasy ConvNet i wykonać jakiś próbny *forward pass* na danych walidacyjnych, aby przekonać się, czy budowa naszej sieci jest poprawna (przynajmniej pod kątem składnowym i numerycznym, tj. czy zgadzają się wymiary tensorów przekazywanych pomiędzy warstwami). Uruchom więc kod z poniższej komórki. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przykładowe predykcje modelu na danych walidacyjnych: tensor([[0.0441, 0.0823, 0.0823, 0.3156, 0.1783, 0.0769, 0.0622, 0.0552, 0.0823,\n",
      "         0.0210],\n",
      "        [0.0135, 0.1119, 0.1289, 0.1119, 0.1556, 0.2022, 0.1119, 0.0343, 0.0181,\n",
      "         0.1119],\n",
      "        [0.1699, 0.1390, 0.1123, 0.0926, 0.0831, 0.0369, 0.0722, 0.0926, 0.0926,\n",
      "         0.1089]], dtype=torch.float64, grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cnn = ConvNet(\n",
    "    input_channels=1,\n",
    "    sample_size=Xval.shape[2],\n",
    "    output_layer_size=num_classes,\n",
    "    kernel_size=3,\n",
    "    padding=0,\n",
    "    stride=1)\n",
    "cnn = cnn.double()\n",
    "pred = cnn(Xval)\n",
    "print(\"Przykładowe predykcje modelu na danych walidacyjnych: \"+str(pred[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbieramy odpowiedzi od każdego wyjściowego neuronu, a każda oznacza prawdopodobieństwo przynależności badanego obrazka do odpowiedniej klasy. Pamiętaj, że nie ma po co przywiązywać się do predykcji otrzymanych na tym etapie - sieć jeszcze nie została niczego nauczona! \n",
    "\n",
    "\n",
    "### Trening sieci neuronowej\n",
    "\n",
    "Napiszmy w takim razie funkcję `train_cnn()`, w której przeprowadzimy trening naszej konwolucyjnej sieci neuronowej. Podobnie, jak poprzednio, wykorzystajmy algorytm optymalizacji Adam (który, jak pamiętamy, potrzebuje odniesienia do parametrów, które ma optymalizować (argument `params` - przekażmy wynik metody `parameters()` na obiekcie naszej klasy ConvNet), stałej uczenia $\\alpha$ (argument `lr` - przekażmy na stałe wartość 0,005), a także stałej regularyzacji $\\lambda$ (argument `weight_decay` - przekażmy na stałe wartość 0,001), a jako funkcję kosztu wykorzystajmy CrossEntropyLoss.\n",
    "\n",
    "Niech zawartość naszej funkcji będzie podobna, jak na poprzednim ćwiczeniu:\n",
    "* Utwórz obiekt klasy ConvNet, a także obiekt zawierający odniesienie do właściwego algorytmu optymalizacji i funkcji kosztu.\n",
    "* Powtarzaj iteracyjnie:\n",
    "    * Przełącz sieć na tryb walidacji, wykonaj *forward pass* na danych walidacyjnych, oblicz wartość kosztu na tych danych i zapisz ją w odpowiedniej zmiennej (pamiętaj o odłączeniu ,,niepotrzebnych'' dla PyTorcha zmiennych metodą `detach()`).\n",
    "    * Przełącz sieć na tryb treningu, wykonaj *forward pass* na danych treningowych, oblicz wartość kosztu na tych danych i zapisz ją w odpowiedniej zmiennej, dokonaj propagacji wstecznej błędu, wykonaj jedną iterację algorytmu optymalizacji, po czym usuń z pamięci obliczone gradienty.\n",
    "    \n",
    "Wyświetlenie zmian kosztu wraz z kolejnymi iteracjami zostało już dla Ciebie napisane. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(Xtrain, ytrain, Xval, yval, num_classes, kernel_size=3, padding=0, stride=1, lambdA=0.001, if_plot=True):\n",
    "    \"\"\"\n",
    "    Wykonaj trening swojej sieci neuronowej zdefiniowanej w klasie NeuralNet \n",
    "    na zadanych danych wejściowych i z określoną stałą regularyzacji lambdA. \\n\n",
    "    Argumenty: \\n\n",
    "    - Xtrain - dane treningowe (torch tensor, shape = (num_samples * percentage_train, input_channels, sample_size, sample_size) ), \\n\n",
    "    - ytrain - etykiety do danych treningowych po one-hot-encodingu\n",
    "        (torch tensor, shape = (num_samples * percentage_train, num_classes) ), \\n\n",
    "    - Xval - dane testowe (torch tensor, shape = (num_samples * percentage_val, input_channels, sample_size, sample_size) ), \\n\n",
    "    - yval - etykiety do danych walidacyjnych po one-hot-encodingu\n",
    "        (torch tensor, shape = (num_samples * percentage_val, num_classes) ), \\n\n",
    "    - num_classes - ilość klas, tj. ile różnych wartości pojawia się w etykietach (int, skalar), \\n\n",
    "    - kernel_size - wielkość filtra użytego do konwolucji (int, skalar) (opcjonalnie, domyślnie 3), \\n\n",
    "    - padding - wielkość ,,ramki'' dodawanej do danych przed konwolucją (int, skalar) (opcjonalnie, domyślnie 0), \\n\n",
    "    - stride - co ile pikseli ma być robiona konwolucja (int, skalar) (opcjonalnie, domyślnie 1), \\n\n",
    "    - lambdA - stała regularyzacji (float, skalar) (opcjonalnie, domyślnie 0.001), \\n\n",
    "    - if_plot - Boolean, decyduje, czy po treningu wyświetlić krzywe uczenia (opcjonalnie, domyślnie True). \\n\n",
    "    Zwraca: cnn - wytrenowana sieć neuronowa, zdefiniowana w klasie ConvNet.\n",
    "    \"\"\"\n",
    "    cnn = ConvNet( \n",
    "        input_channels = Xtrain.shape[1], \n",
    "        sample_size = Xtrain.shape[2],\n",
    "        output_layer_size=num_classes,\n",
    "        kernel_size=kernel_size, \n",
    "        padding=padding, \n",
    "        stride=stride\n",
    "        ) \n",
    "    cnn = cnn.double() \n",
    "    loss_train_vec = [] \n",
    "    loss_val_vec = []  \n",
    "    # ---------------------------- UZUPEŁNIJ KOD ---------------------------------------\n",
    "    # Utwórz obiekt związany z funkcją kosztu - CrossEntropyLoss\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    # Utwórz obiekt związany z metodą optymalizacji - Adam\n",
    "    optimizer = torch.optim.Adam(\n",
    "        cnn.parameters(),\n",
    "        lr=0.001,\n",
    "        weight_decay=lambdA\n",
    "    )  \n",
    "    for i in range(1000):\n",
    "        if if_plot:\n",
    "            # Przełącz sieć w tryb walidacji\n",
    "            cnn.eval()\n",
    "            with torch.no_grad(): \n",
    "                # Wykonaj forward pass na danych walidacyjnych\n",
    "                pred = cnn(Xval)\n",
    "                # Oblicz koszt na tych danych\n",
    "                loss_val = criterion(pred, torch.tensor(yval))\n",
    "                # Zapisz koszt w odpowiedniej zmiennej (loss_val_vec)\n",
    "                loss_val_vec.append(loss_val.item())\n",
    "        # Przełącz sieć w tryb treningu\n",
    "        cnn.train()\n",
    "        # Wykonaj forward pass na danych treningowych\n",
    "        pred = cnn(Xtrain)\n",
    "        # Oblicz koszt na tych danych\n",
    "        loss_train = criterion(pred, torch.tensor(ytrain))\n",
    "        # Wykonaj propagację wsteczną kosztu\n",
    "        loss_train.backward()\n",
    "        # Wykonaj 1 iterację algorytmu optymalizacji\n",
    "        optimizer.step()\n",
    "        # Wyzeruj gradienty\n",
    "        cnn.zero_grad()\n",
    "        # Zapisz koszt do odpowiedniej zmiennej (loss_train_vec)\n",
    "        loss_train_vec.append(loss_train.item())\n",
    "    # ------------------------------------------------------------------------\n",
    "    if if_plot:\n",
    "        print(\"  Zakończono trening sieci.\")\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(loss_train_vec, color='k')\n",
    "        ax.plot(loss_val_vec, color='r')\n",
    "        ax.set_title(\"Krzywe uczenia\")\n",
    "        ax.set_xlabel(\"Iteracja\")\n",
    "        ax.set_ylabel(\"Koszt\")\n",
    "        ax.legend([\"Koszt na danych treningowych\", \"Koszt na danych walidacyjnych\"])\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy, jak zmieniły się predykcje dokonane przez naszą sieć, kiedy czegoś ją nauczyliśmy: powinniśmy widzieć większe zróżnicowanie wyników."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przykładowe predykcje modelu na danych walidacyjnych (po treningu): tensor([[9.4972e-03, 1.2543e-02, 4.7594e-02, 1.5708e-01, 4.7594e-02, 4.0619e-01,\n",
      "         1.1039e-02, 4.7594e-02, 4.7594e-02, 2.1328e-01],\n",
      "        [2.4063e-03, 9.1898e-04, 1.2568e-03, 1.2119e-03, 1.9016e-03, 6.7197e-04,\n",
      "         5.9348e-04, 1.4713e-03, 1.0145e-03, 9.8855e-01],\n",
      "        [8.6530e-04, 2.0759e-04, 2.5674e-03, 8.9841e-04, 1.6237e-04, 8.2291e-04,\n",
      "         2.8444e-04, 2.5674e-03, 9.9124e-01, 3.8869e-04]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "nn = train_cnn(\n",
    "    Xtrain=Xtrain, \n",
    "    ytrain=ytrain_ohe, \n",
    "    Xval=Xval, \n",
    "    yval=yval_ohe, \n",
    "    num_classes=num_classes,\n",
    "    if_plot=False)\n",
    "pred = nn(Xval)\n",
    "print(\"Przykładowe predykcje modelu na danych walidacyjnych (po treningu): \"+str(pred[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predykcja\n",
    "\n",
    "Kolejnym krokiem jest napisanie funkcji, która analizuje prawdopodobieństwa zwracane przez sieć neuronową i zwraca konkretne numery klas, do których powinny należeć analizowane obrazki - przypomnijmy, że z pomocą `torch.argmax()` należy znaleźć indeks klasy, której sieć przyporządkowała najwyższe prawdopodobieństwo. Uzupełnij więc kod funkcji `pred_cnn()`, która wykona taką operację. <font size=\"2\">Nie zapominaj o argumencie `dim`.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_cnn(X, cnn):\n",
    "    \"\"\"\n",
    "    Dokonuje ostatecznej predykcji sieci neuronowej (obiektu NeuralNet) - wskazania klasy - dla danych wejściowych X. \\n\n",
    "    Argumenty: \\n\n",
    "    - X - dane wejściowe (torch tensor, shape = (num_samples, num_features) ), \\n\n",
    "    - nn - model sieci neuronowej, obiekt naszej klasy NeuralNet. \\n\n",
    "    Zwraca: pred - numer klasy wg klasyfikatora właściwy dla X (numpy array, shape = (num_samples,) ).\n",
    "    \"\"\"\n",
    "    # --------- UZUPEŁNIJ KOD -------------\n",
    "    pred = cnn(X)\n",
    "    # -------------------------------------\n",
    "    return pred.argmax(dim=1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zobaczmy, jak wyglądają nasze predykcje dla danych walidacyjnych, kiedy jednoznacznie wskazujemy, do której klasy przypisać daną próbkę (a nie operujemy na prawdopodobieństwach):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przykładowe predykcje dla danych walidacyjnych: [1 5 3]\n"
     ]
    }
   ],
   "source": [
    "pred = pred_cnn(Xval, cnn)\n",
    "print(\"Przykładowe predykcje dla danych walidacyjnych: \"+str(pred[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dobór hiperparametrów z wykorzystaniem biblioteki Optuna\n",
    "\n",
    "Przy budowi sieci konwolucyjnych mamy do czynienia z dużą ilością hiperparametrów - wystarczy przypomnieć *kernel_size*, *padding* czy *stride*. Znalezienie idealnego zestawu hiperparametrów ręcznie (tak, jak robiliśmy to podczas poprzedniego ćwiczenia) może być problematyczne. Użyjemy zatem biblioteki o nazwie Optuna, która pomaga nam w optymalizacji wielu hiperparametrów naraz.\n",
    "\n",
    "Zgodnie z tutorialem [TUTAJ](https://optuna.readthedocs.io/en/stable/tutorial/20_recipes/002_multi_objective.html), musimy najpierw napisać funkcję `objective`, która ma określać to, co chcemy optymalizować --- musi wiedzieć, jakie parametry ma dostosowywać, a także znać miarę, według której można ocenić, czy ,,zbliżamy się'' do celu czy też nie. W naszym przypadku, poszukujemy takiego zestawu hiperparametrów *kernel_size*, *padding* czy *stride*, przy których nasza sieć osiąga możliwie najwyższą dokładność na danych walidacyjnych.\n",
    "\n",
    "Uzupełniony kod funkcji `objective` powinien zawierać więc następujące elementy:\n",
    "* Utworzenie obiektów `trial.suggest_int`, definiujących zakres wartości różnych hiperparametrów, które chcemy przebadać (w naszym przypadku, wszystkie szukane wartości są liczbami całkowitymi).\n",
    "* Przeprowadze *forward pass* na danych walidacyjnych:\n",
    "    * utworzenie obiektu klasy ConvNet i wytrenowanie sieci z pewnym (wybranym przez Optunę) zestawem hiperparametrów,\n",
    "    * dokonanie predykcji (funkcja `pred_cnn`) na danych walidacyjnych,\n",
    "* Obliczenie i zwrócenie dokładności predykcji (przypomnij sobie z poprzednich ćwiczeń trick z `np.where`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, Xtrain, ytrain, Xval, yval, num_classes): \n",
    "    \"\"\"\n",
    "    Funkcja określająca, co ma być optymalizowane przez Optunę. \\n\n",
    "    Argumenty: \\n\n",
    "    - trial - wewnętrzny argument Optuny, \\n\n",
    "    - Xtrain - dane treningowe (torch tensor, shape = (num_samples * percentage_train, input_channels, sample_size, sample_size) ), \\n\n",
    "    - ytrain - etykiety do danych treningowych po one-hot-encodingu\n",
    "        (torch tensor, shape = (num_samples * percentage_train, num_classes) ), \\n\n",
    "    - Xval - dane testowe (torch tensor, shape = (num_samples * percentage_val, input_channels, sample_size, sample_size) ), \\n\n",
    "    - yval - etykiety do danych walidacyjnych po one-hot-encodingu\n",
    "        (torch tensor, shape = (num_samples * percentage_val, num_classes) ), \\n\n",
    "    - num_classes - ilość klas, tj. ile różnych wartości pojawia się w etykietach (int, skalar). \\n\n",
    "    Zwraca: accuracy - dokładność sieci na danych walidacyjnych przy badanych hiperparametrach (skalar, float).\n",
    "    \"\"\"\n",
    "    # ------------------------- UZUPEŁNIJ KOD ------------------------------\n",
    "    # Określ wartości hiperparametru kernel_size, które chcesz przebadać (od 1 do 3, int, bez skali logarytmicznej)\n",
    "    kernel_sizes = trial.suggest_int(\"kernel_size\", 1, 3, log=False)\n",
    "    # Określ wartości hiperparametru padding, które chcesz przebadać (od 1 do 3, int, bez skali logarytmicznej)\n",
    "    paddings = trial.suggest_int(\"padding\", 0, 2)\n",
    "    # Określ wartości hiperparametru stride, które chcesz przebadać (od 1 do 3, int, bez skali logarytmicznej)\n",
    "    strides = trial.suggest_int(\"stride\", 1, 3, log=False)\n",
    "    # Wytrenuj sieć klasy ConvNet z badanymi hiperparametrami\n",
    "    cnn = train_cnn(Xtrain, ytrain, Xval, yval, num_classes, kernel_sizes, paddings, strides)\n",
    "    # Dokonaj predykcji na danych walidacyjnych\n",
    "    pred = pred_cnn(Xval, cnn)\n",
    "    # Oblicz dokładność klasyfikacji\n",
    "    accuracy = (pred == torch.argmax(torch.tensor(yval), dim=1).numpy()).mean()\n",
    "    # -----------------------------------------------------------------------\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolejnym krokiem, po napisaniu funkcji `objective`, jest utworzenie obiektu `study`, który będzie przechowywał wyniki testowania różnych kombinacji wartości hiperparametrów (i dzięki któremu wybierzemy ten optymalny zestaw).\n",
    "* Korzystając z metody `optuna.create_study` (i wskazując w argumencie `direction`, że chcemy maksymalizować optymalizowaną funkcję), utwórz obiekt o nazwie `study`.\n",
    "* Wywołaj na tym obiekcie metodę `optimize` - musisz jej przekazać zdefiniowany wcześniej `objective`, wówczas `study` będzie wiedzieć, co ma optymalizować i w jaki sposób. UWAGA! Musisz zastosować pewien trick opisany [TUTAJ](https://optuna.readthedocs.io/en/stable/faq.html#how-to-define-objective-functions-that-have-own-arguments), aby do funkcji `objective` przekazać własne argumenty $Xtrain$, $ytrain$, $Xval$, $yval$  oraz *num_classes* - proponuję zastosować podejście z lambdą. Jako argument musisz też przekazać ilość prób (losowań zestawu hiperparametrów), które podejmie Optuna (argument `n_trials`) - proponuję w ramach ćwiczeń podać wartość 5, aby czas obliczeń nie był znacząco wydłużony, natomiast w rzeczywistych projektach radzę używać wyższych wartości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-06 21:23:02,810] A new study created in memory with name: no-name-aa4e3b16-8b05-4ecb-b4d4-b8bf46cedfd1\n",
      "[W 2023-11-06 21:26:28,755] Trial 0 failed with parameters: {'kernel_size': 1, 'padding': 2, 'stride': 1} because of the following error: IndexError('Dimension out of range (expected to be in range of [-1, 0], but got 1)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jakub/venv_advanced/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_2987/540652920.py\", line 7, in <lambda>\n",
      "    study.optimize(func=lambda trial: objective(trial, Xtrain, ytrain, Xval, yval, num_classes), n_trials=5)\n",
      "  File \"/tmp/ipykernel_2987/2285466889.py\", line 27, in objective\n",
      "    accuracy = (pred == torch.argmax(torch.tensor(yval), dim=1).numpy()).mean()\n",
      "IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "[W 2023-11-06 21:26:28,757] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Zakończono trening sieci.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb Komórka 21\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Optymalizuj hiperparametry kernel_size, padding i stride - wykonaj optimize() na obiektcie study\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# (funkcję objective przekaż w postaci wyrażenia lambda)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(func\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m trial: objective(trial, Xtrain, ytrain, Xval, yval, num_classes), n_trials\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/venv_advanced/lib/python3.9/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/venv_advanced/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/venv_advanced/lib/python3.9/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/venv_advanced/lib/python3.9/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/venv_advanced/lib/python3.9/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb Komórka 21\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Optymalizuj hiperparametry kernel_size, padding i stride - wykonaj optimize() na obiektcie study\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# (funkcję objective przekaż w postaci wyrażenia lambda)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m study\u001b[39m.\u001b[39moptimize(func\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m trial: objective(trial, Xtrain, ytrain, Xval, yval, num_classes), n_trials\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "\u001b[1;32m/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb Komórka 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m pred \u001b[39m=\u001b[39m pred_cnn(Xval, cnn)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Oblicz dokładność klasyfikacji\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m accuracy \u001b[39m=\u001b[39m (pred \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39;49margmax(torch\u001b[39m.\u001b[39;49mtensor(yval), dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mnumpy())\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# -----------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------ Dobór hiperparametrów ------------------------\n",
    "# ---------------------------- UZUPEŁNIJ KOD ----------------------------\n",
    "# Utwórz obiekt o nazwie study (użyj optuna.create_study, nie zapominaj o argumencie direction)\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "# Optymalizuj hiperparametry kernel_size, padding i stride - wykonaj optimize() na obiektcie study\n",
    "# (funkcję objective przekaż w postaci wyrażenia lambda)\n",
    "study.optimize(func=lambda trial: objective(trial, Xtrain, ytrain, Xval, yval, num_classes), n_trials=5)\n",
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli optymalizacja przebiegła pomyślnie, zobaczmy, jaki zestaw hiperparametrów okazał się najlepszy! Obiekt `study` przechowuje najlepsze wartości w słowniku `best_params` - wystarczy wyszukać po nazwie nadanej hiperparametrowi podczas tworzenia `objective`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No trials are completed yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb Komórka 23\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Wyświetl rezultat optymalizacji\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNajwyższa dokładność podczas optymalizacji: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(study\u001b[39m.\u001b[39;49mbest_value))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# ------------------------- UZUPEŁNIJ KOD -------------------------------\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jakub/Deep-Learning/Lab_03_Konwolucyjne_sieci_neuronowe.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m optimal_kernel_size \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/venv_advanced/lib/python3.9/site-packages/optuna/study/study.py:128\u001b[0m, in \u001b[0;36mStudy.best_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbest_value\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[1;32m    118\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the best objective value in the study.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \n\u001b[1;32m    120\u001b[0m \u001b[39m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \n\u001b[1;32m    126\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     best_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_trial\u001b[39m.\u001b[39mvalue\n\u001b[1;32m    129\u001b[0m     \u001b[39massert\u001b[39;00m best_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     \u001b[39mreturn\u001b[39;00m best_value\n",
      "File \u001b[0;32m~/venv_advanced/lib/python3.9/site-packages/optuna/study/study.py:157\u001b[0m, in \u001b[0;36mStudy.best_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_multi_objective():\n\u001b[1;32m    152\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    153\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA single best trial cannot be retrieved from a multi-objective study. Consider \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39musing Study.best_trials to retrieve a list containing the best trials.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m     )\n\u001b[0;32m--> 157\u001b[0m \u001b[39mreturn\u001b[39;00m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_storage\u001b[39m.\u001b[39;49mget_best_trial(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_study_id))\n",
      "File \u001b[0;32m~/venv_advanced/lib/python3.9/site-packages/optuna/storages/_in_memory.py:234\u001b[0m, in \u001b[0;36mInMemoryStorage.get_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    231\u001b[0m best_trial_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_studies[study_id]\u001b[39m.\u001b[39mbest_trial_id\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m best_trial_id \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo trials are completed yet.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    235\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_studies[study_id]\u001b[39m.\u001b[39mdirections) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    236\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mBest trial can be obtained only for single-objective optimization.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: No trials are completed yet."
     ]
    }
   ],
   "source": [
    "# Wyświetl rezultat optymalizacji\n",
    "print(\"Najwyższa dokładność podczas optymalizacji: \" + str(study.best_value))\n",
    "# ------------------------- UZUPEŁNIJ KOD -------------------------------\n",
    "optimal_kernel_size = 0\n",
    "print(\"Najlepszy kernel_size: \" + str(optimal_kernel_size))\n",
    "optimal_padding = 0\n",
    "print(\"Najlepszy padding: \" + str(optimal_padding))\n",
    "optimal_stride = 0\n",
    "print(\"Najlepszy stride: \" + str(optimal_stride))\n",
    "# -----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mając wybrane wartości hiperparametrów, czas uruchomić właściwy trening naszej konwolucyjnej sieci neuronowej! Uruchom po prostu poniższy kod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mUruchomienie komórek z elementem „/bin/python3” wymaga pakietu ipykernel.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# ---------------- Trening sieci --------------\n",
    "cnn = train_cnn(\n",
    "    Xtrain=Xtrain, \n",
    "    ytrain=ytrain_ohe, \n",
    "    Xval=Xval, \n",
    "    yval=yval_ohe, \n",
    "    num_classes=num_classes,\n",
    "    kernel_size=optimal_kernel_size,\n",
    "    padding=optimal_padding,\n",
    "    stride=optimal_stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak zwykle, sprawdź, czy na wykresie krzywych uczenia nie obserwujesz znaczącego *overfittingu* (czy krzywa dla zestawu walidacyjnego nie rośnie przy dalszym spadku krzywej dla zestawu treningowego). Jeśli wszystko jest w porządku, sprawdźmy dokładność naszego modelu także na danych testowych z zestawu `digits`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mUruchomienie komórek z elementem „/bin/python3” wymaga pakietu ipykernel.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# ----------------- Predykcja i sprawdzenie działania -------------------\n",
    "pred = pred_cnn(Xtrain, cnn)\n",
    "accuracy = np.mean(pred==ytrain)\n",
    "print(\"Dokładność modelu na danych treningowych: \"+str(accuracy*100)+'%')\n",
    "pred = pred_cnn(Xval, cnn)\n",
    "accuracy = np.mean(pred==yval)\n",
    "print(\"Dokładność modelu na danych walidacyjnych: \"+str(accuracy*100)+'%')\n",
    "pred = pred_cnn(Xtest, cnn)\n",
    "accuracy = np.mean(pred==ytest)\n",
    "print(\"Dokładność modelu na danych testowych: \"+str(accuracy*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Wykorzystanie gotowej architektury - AlexNet\n",
    "\n",
    "Badacze tematyką klasyfikacji obrazów zajmują się od lat. Istnieje wiele gotowych architektur konwolucyjnych sieci neuronowych, które zostały wykrenowane do oceny, co znajduje się na przekazany jej obrazku. Jedną z nich jest AlexNet, wytrenowana na dużym zbiorze zdjęć ImageNet, która rozróżnia 1000 klas obiektów na zdjęciach. AlexNet składa się z pięciu warstw konwolucyjnych, trzech wastw *max pooling*, oraz trzech wastw *fully-connected* (czyli liniowych) na końcu, wewnątrz używa funkcji aktywacji ReLU, a jedynie na warstwie wyjściowej - funkcji Softmax. Tak prezentuje się jej architektura:\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/Argenni/GUiAO_lab/main/rys/05_alexnet.png'/>\n",
    "\n",
    "<font size=\"1\">Grafika: hackmd.io / Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton, 2012 </font>\n",
    "</div>\n",
    "\n",
    "Jej implementację (wraz z wagami) można pobrać z pomocą PyTorcha. Możemy ją zaimportować do naszego projektu, pobrać etykiety klas używanych przez ImageNet (z repozytorium twórców ImageNet), a następnie dokonać klasyfikacji dowolnego zdjęcia! Musimy jedynie pamiętać, aby odpowiednio zdjęcie przekształcić: musi ono mieć wymiary 3x224x224 (oczywiście jako zdjęcie RGB, stąd 3 kanały), a także być wstępnie znormalizowane. Poniższy fragment kodu, tworzony w oparciu o tutorial [TUTAJ](https://pytorch.org/hub/pytorch_vision_alexnet/) realizuje właśnie wspomniane wyżej zadania:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mUruchomienie komórek z elementem „/bin/python3” wymaga pakietu ipykernel.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# ---------------------- Klasyfikacja obrazów z AlexNet -----------------------------\n",
    "# Import niezbędnych bibliotek\n",
    "! python -m pip install torch==2.0.1\n",
    "! python -m pip install numpy==1.22.3\n",
    "! python -m pip install matplotlib==3.4.2\n",
    "! python -m pip install wget==3.2\n",
    "! python -m pip install PIL\n",
    "! python -m pip install torchvision==0.15.2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import wget\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Importuj AlexNet - w pełni wytrenowany model\n",
    "alexnet = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "alexnet.eval()\n",
    "# Pobierz nazwy klas, jakie posiada ImageNet\n",
    "if not os.path.exists(\"utils/imagenet_classes.txt\"):\n",
    "    wget.download(\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", out=\"utils/imagenet_classes.txt\")\n",
    "with open(\"utils/imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "    \n",
    "# Importuj przykładowe zdjęcie psa\n",
    "if not os.path.exists(\"utils/dog.jpg\"): \n",
    "    wget.download(\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", out=\"utils/dog.jpg\")\n",
    "# Przekształć zdjęcie, by AlexNet mógł je przetworzyć\n",
    "input_image = Image.open(\"utils/dog.jpg\")\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czas na Ciebie! Dokonaj klasyfikacji pobranego zdjęcia za pomocą AlexNet. Wykonaj *forward pass* na zdjęciu zapisanym w zmiennej `input_batch`, wywołując `alexnet` jak każdy inny model PyTorcha, wyszukaj klasę z najwyżej ocenionym przez AlexNet prawdopodobieństwem (wykorzystaj znów `torch.argmax`) i w pobranym słowniku etykiet `categories` wyszukaj nazwę odpowiedniej klasy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mUruchomienie komórek z elementem „/bin/python3” wymaga pakietu ipykernel.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# ------------------------------ UZUPEŁNIJ KOD --------------------------------\n",
    "# Dokonaj klasyfikacji zdjęcia\n",
    "with torch.no_grad():\n",
    "    output = 0\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "pred_class = 0\n",
    "# Odczytaj nazwę klasy\n",
    "pred_category = 0\n",
    "# -----------------------------------------------------------------------------\n",
    "plt.imshow(input_image)\n",
    "print(\"\\nPredykcja: \" + pred_category + \" (\" + str(probabilities[pred_class].numpy()) + \" pewności)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możesz oczywiście samodzielnie poeksperymentować, podmieniając zdjęcia, których klasyfikacji ma dokonać AlexNet.\n",
    "\n",
    "\n",
    "## 5. Pytania kontrolne\n",
    "1. Opisz bardzo krótko, na czym polega zasada działania konwolucyjnych sieci neuronowych.\n",
    "2. Na co wpływa wartość hiperparametru: *kernel_size* / *padding* / *stride* ?\n",
    "3. Z jakich warstw zazwyczaj składa się konwolucyjna sieć neuronowa?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('vscode0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "778cfed3981b96449a29dc7b86e438e34449205630b92b8bee0fcf8135b84476"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
