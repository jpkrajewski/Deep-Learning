{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "<font size=\"5\">\n",
    "\n",
    "Laboratorium z przedmiotu: \\\n",
    "**Głębokie uczenie i analiza obrazów**\n",
    "\n",
    "Ćwiczenie 2: \\\n",
    "**Budowa i optymalizacja sztucznej sieci neuronowej**\n",
    "\n",
    "</font>\n",
    "\n",
    "\\\n",
    "Marta Szarmach \\\n",
    "Zakład Telekomunikacji Morskiej \\\n",
    "Wydział Elektryczny \\\n",
    "Uniwersytet Morski w Gdyni\n",
    "\n",
    "09.2023\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "# 1. Wprowadzenie\n",
    "\n",
    "**Uczenie głębokie** jest podzbiorem algorytmów uczenia maszynowego, wykorzystującym złożone, wielowarstwowe modele - najczęściej **sieci neuronowe**, które z kolei są strukturami imitującymi ludzki układ nerwowy, złożonymi z jednostek mogących ulegać aktywacji - **sztucznych neuronów** - i połączeń między nimi, umiejącymi odnajdywać nawet skomplikowane, nieliniowe zależności w danych. Uczenie głębokie świetnie sprawdza się do analizy danych odzwierciedlających ludzkie zmysły: obrazów (sieci konwolucyjne), fragmentów mowy (sieci rekurencyjne). Sieci neuronowe wykorzystywane są do rozwiązywania znanych nam już rodzajów problemów (takich, jak regresja, klasyfikacja czy wykrywanie anomalii).  \n",
    "\n",
    "Za pomocą pierwszej warstwy sieci, tzw. **warstwy wejściowej**, do sieci neuronowej wprowadzane są dane $x=a^{(1)}$ (warstwa ta zazwyczaj zbudowana jest z tylu neuronów, ile mamy cech w danych wejściowych). Dane te następnie ulegają przekształceniom w $l$ **warstwach ukrytych** (zazwyczaj realizujących przekształcenia liniowe $\\Theta^{(l)} \\cdot a^{(l)}$, a także nieliniowe z wykorzystaniem **funkcji aktywacji** $f(z)$, którym zawdzięczamy tak naprawdę ,,moc'' sieci neuronowych - bez tych funkcji wprowadzających nieliniowości, nasze modele byłyby zwykłymi przekształceniami liniowymi i nie umiałyby uczyć się złożonych funkcji!). Neurony umieszczone w ostatniej, **wyjściowej warstwie**, decydują o postaci ostatecznej predykcji $h_\\theta(x)$ - zazwyczaj w zagadnieniach regresji na ostatniej warstwie umieszczany jest 1 neuron, który zwraca predykcję w postaci jakiejś liczby rzeczywistej, a w zagadnieniach klasyfikacji na ostatniej warstwie mamy tyle neuronów, ile klas, do których może należeć analizowana próbka danych (każdy neuron zwraca liczbę będącą prawdopodobieństwiem należenia tej próbki do danej klasy).\n",
    "\n",
    "Ogólnie przepływ danych w ,,zwykłej'' sieci neuronowej można zapisać tak:\n",
    "\\begin{equation*}\n",
    "    z^{(l)} = \\Theta^{(l)} \\cdot a^{(l-1)}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "    a^{(l)} = f(z^{(l)})\n",
    "\\end{equation*}\n",
    "\n",
    "gdzie:\n",
    "* macierz $\\Theta^{(l)}$ określa wagi połączeń pomiędzy neuronami z $(l-1)$ a $l$-tej warstwy i to ona zawiera **parametry** wyuczone w ramach treningu sieci,\n",
    "* funkcja aktywacji $f(z)$ może przybierać postać między innymi:\n",
    "    * funkcji ReLU (ang. *Rectified Linear Unit*): $f(z) = \\max(0,z)$,\n",
    "    * znanej nam już funkcji sigmoid: $ f(z) = \\frac{1}{1 + \\exp(-z)} $,\n",
    "    * funkcji Softmax, która zwraca znormalizowane (sumujące się do 1) prawdopodobieństwa należenia próbki do $i$-tej klasy: \n",
    "    $ f_i(z) = \\frac{e^{z_i}}{\\sum_{j=1}^{\\textrm{num\\_class}} e^{z_j}} $\n",
    "\n",
    "Podczas treningu sieci neuronowych, podobnie jak w przypadku trenowania ,,klasycznych'' algorytmów uczenia maszynowego, zależy nam na doborze takich parametrów, które minimalizują funkcję kosztu $J(\\Theta)$, tj. najlepiej oddają zależności pomiędzy danymi. Do optymalizacji funkcji kosztu możemy używać różnych algorytmów, takich jak znany nam już *Gradient Descent* czy Adam. Problemem jest jednak wyznaczanie gradientów (niezbędnych do optymalizacji w kierunku najszybszego spadku funkcji kosztu) w tak skomplikowanych, wielowarstwowych strukturach, jakimi są sieci neuronowe. W tym celu stosuje się algorytm **propagacji wstecznej**, który polega na przekazywaniu informacji o tym, jaki błąd w ostateczną predykcję ($\\delta$) wprowadzają neurony na każdej warstwie w ,,dół'' sieci, od warstwy wyjściowej, przez ukryte, do wejściowej, uzwględniając na każdej warstwie ,,modyfikację'' tego błędu wprowadzaną przez tąż warstwę. Gradienty, z pomocą reguły łańcuchowej, liczone są na podstawie tychże błędów. Ogólne wzory przedstawiają się następująco:\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\delta^{(l-1)} = \\frac{\\partial J(\\Theta)}{\\partial z^{(l-1)}} = (\\Theta^{(l)})^T \\cdot \\delta^{(l)} * f'^{(l-1)} (z^{(l-1)})\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\frac{\\partial J(\\Theta)}{\\partial \\Theta^{(l)}} = \\delta^{(l)} \\cdot (a^{l-1})^T\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/Argenni/GUiAO_lab/main/rys/03_neural_network.png'/>\n",
    "\n",
    "</div>\n",
    "\n",
    "Podczas treningu musimy starać się zachować równowagę pomiędzy nadmiernym *bias*em (prostotą) a wariancją (złożonością) naszej sieci - przede wszystkim chcemy, żeby nasza sieć umiała dobrze generalizować, tj. wyciągać wnioski o danych i umieć radzić sobie także z danymi, których wcześniej nie widziała. Jeśli nasza sieć świetnie odzwierciedla dane treningowe, ale słabo radzi sobie na pozostałych zestawach, mamy do czynienia z tzw. **przeuczeniem** (ang. *overfitting*) naszej sieci. Aby temu zapobiec i poprawić osiągi naszej sieci na nowych danych, możemy (oprócz dostarczenia modeli większej ilości danych treningowych) zastosować szereg praktyk:\n",
    "* **regularyzację**, tj. dodanie do funkcji kosztu składnika $||\\theta||_2$ zależnego od wartości parametrów, który powoduje ,,karanie'' sieci za budowanie zbyt skomplikowanych hipotez,\n",
    "* ***dropout***, czyli usuwanie losowo pewnych neuronów z sieci, zmniejszając w ten sposób jej skomplikowanie i zmuszając inne neurony do lepszej generalizacji,\n",
    "* odpowiedni dobór hiperparametrów (tj. wartości, od których zależy działanie naszego modelu, ale nie są wyznaczane w trakcie treningu); w przypadku sieci neuronowych mogą to być:\n",
    "    * ilość neuronów na każdej warstwie,\n",
    "    * ilość warstw,\n",
    "    * stała uczenia $\\alpha$, określająca wpływ wyliczonych gradientów na aktualizację wag,\n",
    "    * stała regularyzacji $\\lambda$, określająca wpływ składnika $||\\theta||_2$ na funkcję kosztu (im większa lambda, tym silniejszy efekt regularyzacji).\n",
    "\n",
    "Pisanie wszystkich tych rzeczy, od przepływu danych, przez propagację wsteczną, aż do różnych innych warstw sieci neuronowych ,,od zera'' może być problematyczne - całe szczęście, że mamy biblioteki, które robią to za nas! Nie dość, że mają one gotowe ,,bloczki'' do budowy sieci neuronowych, to jeszcze same śledzą, w jaki sposób dane przepływają w naszych sieciach i przeprowadzają propagarcję wsteczną. Przykładami są PyTorch, ktorego to będziemy dziś używać, TensorFlow czy Keras.\n",
    "\n",
    "\n",
    "\n",
    "# 2. Cel ćwiczenia\n",
    "\n",
    "**Celem niniejszego ćwiczenia** jest zapoznanie się z budową sztucznych sieci neuronowych poprzez:\n",
    "* implementacji architektury sztucznej sieci neuronowej o niewielkiej ilości warstw z wykorzystaniem biblioteki PyTorch i języka programowania Python,\n",
    "* obserwacji, jakie elementy tej architektury można modyfikować (hiperparametry), a które elementy uczone są w wyniku treningu modelu (parametry).\n",
    "\n",
    "\n",
    "# 3. Stanowisko laboratoryjne\n",
    "\n",
    "Do wykonania niniejszego ćwiczenia niezbędne jest stanowisko laboratoryjne, składające się z komputera klasy PC z zainstalowanym oprogramowaniem:\n",
    "* językiem programowania Python (w wersji 3.8),\n",
    "* IDE obsługującym pliki Jupyter Notebook (np. Visual Studio Code z rozszerzeniem ipykernel).\n",
    "\n",
    "\n",
    "# 4. Przebieg ćwiczenia\n",
    "## 4.1. Implementacja 3-warstwowej sieci neuronowej z wykorzystaniem biblioteki PyTorch\n",
    "\n",
    "Na początku wykonaj poniższy fragment kodu, aby zaimportować biblioteki niezbędne do wykonania poniższego ćwiczenia:\n",
    "* **PyTorch** - biblioteka wspomagająca budowanie architektur sieci neuronowych, posiadająca wbudowane moduły odpowiadające różnym warstwom sieci neuronowych, automatyczne obliczanie gradientów (*autograd*) niezbędne do przeprowadzenia treningu sieci neuronowych,\n",
    "* **NumPy** - biblioteka umożliwiająca wykonywanie wysoko zoptymalizowanych obliczeń matematycznych na objektach typu *numpy array* (wielowymiarowych tablic),\n",
    "* **Matplotlib** - biblioteka wspomagająca wizualizację pracy czy analizę danych poprzez wyświetlanie wykresów,\n",
    "* **Scikit-learn** - biblioteka zawierająca gotowe implementacje wielu algorytmów klasycznego uczenia maszynowego, a także zbiory danych czy metryki. Tutaj skorzystamy ze zbioru danych iris - `datasets.load_iris`, metody `model_selection.train_test_split` służącej do podziału danych na zestaw treningowy i testowy oraz klasy `preprocessing.StandardScaler`, za pomocą której standaryzacji naszych danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m pip install torch==1.12.1\n",
    "! python -m pip install numpy==1.22.3\n",
    "! python -m pip install scikit-learn==0.24.2\n",
    "! python -m pip install matplotlib==3.4.2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# (dla zachowania powtarzalności wyników)\n",
    "np.random.seed(10) \n",
    "torch.manual_seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie i przygotowanie danych\n",
    "\n",
    "Na początku przygotujmy dane, na których będziemy dziś pracować. Tym razem korzystać będziemy z całego zbioru iris (nie będziemy się ograniczać jedynie do 2 klas). Uruchom kod z poniższej komórki, aby:\n",
    "* wczytać oryginalne dane z zestawu iris do zmiennej $X$ i ich etykiety do zmiennej $y$,\n",
    "* obliczyć (z wykorzystaniem metody `numpy.unique`, wyszukującej unikatowe wartości z tablicy, której opis znajdziesz [TUTAJ](https://numpy.org/doc/stable/reference/generated/numpy.unique.html)) w automatyczny sposób ilość klas występujących w naszym zbiorze danych (tj. ilość unikalnych wartości w etykietach) - wiemy, że powinno ich być 3,\n",
    "* z pomocą `train_test_split` wydzielić 60% danych (90 próbek) jako zestaw treningowy $Xtrain$, a pozostałą część danych po równo podzielić na zestaw walidacyjny $Xval$ i testowy $Xtest$ (po 20%, czyli 30 próbek),\n",
    "* z pomocą klasy `StandardScaler` i metody `fit_transform` dokonać standaryzacji każdego zbioru danych,\n",
    "* przygotować etykiety tak, aby współpracowały z funkcją kosztu `CrossEntropyLoss`, którą zastosujemy przy treningu naszej sieci - odpowiedź od każdego neuronu zbierana będzie w osobnej kolumnie tablicy, dlatego nasze etykiety w formacie (*num_samples*,), zawierające wartości 0,1,2 przekształcimy za pomocą one-hot-encodingu do postaci (*num_samples*, *num_classes*), np. 2 -> [0,0,1]\n",
    "* ostatecznie, zestandaryzowane dane i przekształcone etykiety, które będą przekazywane sieci neuronowej, przekształcimy do formatu    `torch.tensor`, aby były zrozumiałe dla PyTorcha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Inicjalizacja ----------------------------\n",
    "# Wczytanie danych\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "num_classes = (np.unique(y)).shape[0]\n",
    "# Podziel dane na zestaw treningowy (60%), walidacyjny (20%) i testowy (20%) z wykorzystaniem metody train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,train_size=0.6)\n",
    "Xval, Xtest, yval, ytest = train_test_split(Xtest,ytest,train_size=0.5)\n",
    "# Dokonaj standaryzacji danych z wykorzystaniem klasy StandardScaler\n",
    "scaler = StandardScaler()\n",
    "Xtrain_norm = scaler.fit_transform(Xtrain)\n",
    "Xval_norm = scaler.fit_transform(Xval)\n",
    "Xtest_norm = scaler.fit_transform(Xtest)\n",
    "# Dokonaj one-hot-encodingu etykiet z zestawu treningowego i walidacyjnego\n",
    "ytrain_ohe = np.identity(num_classes)[ytrain]\n",
    "yval_ohe = np.identity(num_classes)[yval]\n",
    "# Przekonwertuj dane wejściowe na tensory, by mogłby być obsługiwane przez PyTorch\n",
    "Xtrain_norm = torch.tensor(Xtrain_norm)\n",
    "ytrain_ohe = torch.tensor(ytrain_ohe) \n",
    "Xval_norm = torch.tensor(Xval_norm) \n",
    "yval_ohe = torch.tensor(yval_ohe)\n",
    "Xtest_norm = torch.tensor(Xtest_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Określenie struktury naszej sieci neuronowej\n",
    "\n",
    "W kolejnym kroku zdefiniujemy strukturę naszej sieci neuronowej, korzystając z klas dostępnych w bibliotece PyTorch! Zrobimy to w naszej własnej klasie - nazwijmy ją `NeuralNet` - która musi dziedziczyć z klasy `torch.nn.Module`. Ogólny przewodnik po tworzeniu klasy opisującej strukturę sieci neuronowej w PyTorchu dostępny jest [TUTAJ](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html) - zwróć uwagę, że klasa musi koniecznie zawierać minimum dwie metody:\n",
    "* metodę-konstruktor `__init__()` - w której umieszczamy w **obiektach** przekształcenia reprezentujące warstwy tworzące naszą sieć, takie jak:\n",
    "    * `torch.nn.Linear` - opisujące liniowe przekształcenie pomiędzy sąsiednimi warstwami (to tu modelowane jest $\\Theta$, dlatego musimy zdefiniować ilość neuronów na warstwie ,,wcześniejszej'' (`in_features`) i ,,późniejszej'' (`out_features`)) [TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html).\n",
    "    * `torch.nn.ReLU` - realizujące funkcję aktywacji ReLU [TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html),\n",
    "    * `torch.nn.Dropout` - realizujące *dropout* (musimy podać prawdopodobieństwo wykluczenia neuronu) [TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html),\n",
    "    * `torch.nn.Softmax` - realizujące funkcję aktywacji softmax [TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html) (Softmax chce, aby w argumencie `dim` jawnie określić, według któr sumowanie ma dać łącznie wartość 1 - w naszym przypadku, chcemy sumować po odpowiedziach neuronów (`dim=1`), a nie próbkach w batchu (`dim=0`)),\n",
    "    * `torch.nn.Sequential` - stanowiące ,,kontener'', w którym możemy łączyć różne z powyższych bloków ze sobą [TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html).\n",
    "    \n",
    "    Do tej metody przekazujemy argumenty niezbędne podczas tworzenia obiektu będącego naszą siecią neuronową (np. ilość neuronów na poszczególnych warstwach).\n",
    "* metodę `forward()` - w której określamy przepływ danych pomiędzy warstwami określonymi w `__init__` (jakie dane wchodzą, jak są przetwarzane i co zwraca nasza sieć) - kolejne warstwy są tutaj ,,wywoływane''. Do tej metody przekazujemy argumenty niezbędne do wykonania *forward pass*, np. dane wejściowe.\n",
    "\n",
    "Uzupełnij zatem poniższy kod! Niech nasza sieć neuronowa składa się z następujących warstw: \n",
    "`Linear` -> `Dropout` -> `ReLU` -> `Linear` -> `Softmax`.\n",
    "Na pierwszej warstwie (wejściowej) ma być tyle neuronów, ile cech w danych wejściowych (tutaj: 4), na drugiej (ukrytej), na drugiej pewną ilość (założyłam tutaj 8), a na ostatniej - tyle, ile klas (czyli 3). Prawdopodobieństwo odrzucenia neuronu niech wynosi 0,25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Model sztucznej sieci neuronowej zbudowanej z 3 warstw \n",
    "    (Linear + Dropout + Relu) -> (Linear + Softmax)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_layer_size, output_layer_size, hidden_layer_size = 8):\n",
    "        super().__init__()\n",
    "        # ------- UZUPEŁNIJ KOD -----------------------------------------------\n",
    "        # Zdefiniuj budowę swojej sieci\n",
    "        # 1. Połączenie warstwy wejściowej z ukrytą\n",
    "        self.input_to_hidden = torch.nn.Sequential(\n",
    "            # a) Warstwa liniowa (uważnie zdefiniuj rozmiary macierzy wag!)\n",
    "            torch.nn.Linear(input_layer_size),\n",
    "            # b) Dropout (niech neuron zostanie usunięty z prawdopodobieństwem 0.25)\n",
    "            torch.nn.Dropout(0.25),\n",
    "            # c) Funkcja aktywacji ReLU\n",
    "            torch.nn.ReLU()\n",
    "            )\n",
    "        # 2. Połączenie warstwy ukrytej z wyjściową:\n",
    "        self.hidden_to_output = torch.nn.Sequential(\n",
    "            # a) Warstwa liniowa\n",
    "            \n",
    "            # b) Funkcja aktywacji Softmax (pamiętaj o zdefiniowaniu argumentu dim)\n",
    "            \n",
    "            )\n",
    "        # --------------------------------------------------------------------\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Zdefiniuj przepływ danych w swojej sieci:\n",
    "        # 1. Niech dane wejściowe X przekazane zostaną do warstwy ukrytej (input_to_hidden)\n",
    "        X = 0\n",
    "        # ------- UZUPEŁNIJ KOD ---------------------\n",
    "        # 2. Niech dane z warstwy ukrytej przekazane zostaną do warstwy wyjściowej (hidden_to_output)\n",
    "        X = 0\n",
    "        # -------------------------------------------\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spróbujmy utworzyć obiekt tejże klasy i wykonać jakiś próbny *forward pass*, aby przekonać się, czy budowa naszej sieci jest poprawna (przynajmniej pod kątem składnowym i numerycznym, tj. czy zgadzają się wymiary tensorów przekazywanych pomiędzy warstwami). Uruchom więc kod z poniższej komórki. \n",
    "\n",
    "Pamiętajmy, że na ostatniej warstwie naszej sieci znajdują się 3 neurony - tyle, ile klas, do których mogą należeć analizowane przez nią dane. Wynika z tego, że na wyjściu sieci neuronowej otrzymamy 3 różne wartości. Jako że zastosowaliśmy na warstwie wyjściowej funkcję aktywacji Softmax, każdą z tych 3 wartości powinniśmy utożsamiać z prawdopodobieństwem, że badana próbka danych należy do klasy związanej z danym neuronem. Jako że sieć jeszcze nie została niczego nauczona, nie jest pewna, do której klasy powinny należeć badane próbki danych, a więc aktywacje neuronów (prawdopodobieństwa) powinny mieć wartości zbliżone do 0,33. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNet(input_layer_size=X.shape[1],output_layer_size=num_classes)\n",
    "nn = nn.double()\n",
    "pred = nn(Xval_norm)\n",
    "print(\"Przykładowe predykcje modelu na danych walidacyjnych: \"+str(pred[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening sieci neuronowej\n",
    "\n",
    "Po zbudowaniu naszej sieci neuronowej, czas ją czegoś nauczyć! Zgodnie z oficjalnymi poradnikami ([TUTAJ](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html) i [TUTAJ](https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html)), ogólnie rzecz biorąc, aby wytrenować sieć neuronową w PyTorchu, należy wykonać kilka następujących po sobie kroków.\n",
    "* Utwórz obiekt klasy zdefiniowanej chwilę temu - zawierającej budowę naszej sieci neuronowej. Metoda `parameters()` tego obiektu stanowi odniesienie do parametrów modelu, które będą optymalizowane w trakcie treningu.\n",
    "* Z gotowych PyTorchowych klas, wybierz funkcję kosztu oraz algorytm optymalizacji, które posłużą nam podczas treningu - skorzystaj np. z  `Cross Entropy Loss` ([TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)) oraz optymalizatora `Adam` ([TUTAJ](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)), zapisując je jako osobne obiekty. Adam potrzebuje min. następujących argumentów:\n",
    "    * odniesienia do parametrów, które ma optymalizować (patrz wyżej!) (argument `params`),\n",
    "    * stałej uczenia $\\alpha$ (argument `lr`),\n",
    "    * stałej regularyzacji $\\lambda$ (argument `weight_decay` - przekażmy jej zawartość zmiennej o nazwie `lambdA`, o której więcej powiemy za chwilę).\n",
    "* Przełącz sieć na tryb treningu (jest to istotne z punktu widzenia niektórych technik, takich tak Dropout czy BatchNorm - tak, by sieć wiedziała, w jaki sposób wykonać pewne operacje) - wywołaj z modelu metodę `train()`.\n",
    "*  Powtarzaj iteracyjnie:\n",
    "    * wykonaj *forward pass* na danych treningowych - tj. ,,wywołaj'' utworzony wcześniej obiekt, jako argument podając zmienną przechowującą dane treningowe,\n",
    "    * oblicz wartość kosztu przy obecnej iteracji, wywołując obiekt związany z funkcją kosztu, jako argumenty podając dwa porównywane wektory (odpowiedzi sieci z *forward pass* oraz docelowe odpowiedzi treningowe),\n",
    "    * wymuś na PyTorchu wykonanie propagacji wstecznej - niech zadzieje się magia! wystarczy, że na obiekcie, którego wartości mają być propagowane (czyli obliczonym chwilę wcześniej koszcie), wywołasz metodę `backward()`,\n",
    "    * mając obliczone w wyniku propagacji wstecznej gradienty, wymuś na PyTorchu aktualizację parametrów - wystarczy, że wykonasz na obiekcie związanym z algorytmem optymalizacji metodę `step()`,\n",
    "    * usuń obliczone gradienty, tak, by nie miały wpływu na kolejne iteracje (metodą `zero_grad()` na obiekcie z algorytmem optymalizacji),\n",
    "    * miło by było zapisać wartość kosztu do pewnej zmiennej, aby móc potem wyświetlić, jak koszt się zmieniał w trakcie treningu i czy nie doszło do przeuczenia - z tego samego powodu, warto jest całość powtórzyć też (bez liczenia gradientów i aktualizacji wag!) na zestawie walidacyjnym (w trybie ewaluacji).\n",
    "    <font size=\"2\">Metoda `detach()` powoduje ,,oderwanie'' tensora od silnika PyTorcha - po to, by nie były niepotrzebnie liczone dla niego gradienty, które zabierałyby tylko pamięć i moc obliczeniową.</font>\n",
    "\n",
    "Uzupełnij zatem fragmety funkcji `train_nn()` z poniższej komórki, aby to wszystko wdrożyć! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(Xtrain, ytrain, Xval, yval, num_classes, lambdA, if_plot=True):\n",
    "    \"\"\"\n",
    "    Wykonaj trening swojej sieci neuronowej zdefiniowanej w klasie NeuralNet \n",
    "    na zadanych danych wejściowych i z określoną stałą regularyzacji lambdA. \\n\n",
    "    Argumenty: \\n\n",
    "    - Xtrain - dane treningowe (torch tensor, shape = (num_samples * percentage_train, num_features) ), \\n\n",
    "    - ytrain - etykiety do danych treningowych po one-hot-encodingu\n",
    "        (torch tensor, shape = (num_samples * percentage_train, num_classes) ), \\n\n",
    "    - Xval - dane testowe (torch tensor, shape = (num_samples * percentage_val, num_features) ), \\n\n",
    "    - yval - etykiety do danych walidacyjnych po one-hot-encodingu\n",
    "        (torch tensor, shape = (num_samples * percentage_val, num_classes) ), \\n\n",
    "    - num_classes - ilość klas, tj. ile różnych wartości pojawia się w etykietach (int, skalar), \\n\n",
    "    - lambdA - stała regularyzacji (int, skalar), \\n\n",
    "    - if_plot - Boolean, decyduje, czy po treningu wyświetlić krzywe uczenia. \\n\n",
    "    Zwraca: nn - wytrenowana sieć neuronowa, zdefiniowana w klasie NeuralNet.\n",
    "    \"\"\"\n",
    "    nn = NeuralNet( # Tworzymy obiekt naszej klasy NeuralNet,\n",
    "        input_layer_size=Xtrain.shape[1], # gdzie na warstwie wejściowej ma być tyle neuronów, ile cech X,\n",
    "        output_layer_size=num_classes) #  a na warstwie wyjściowej tyle neuronów, ile potencjalnych klas.\n",
    "    nn = nn.double() # (dla ujednolicenia formatów zmiennych)\n",
    "    loss_train_vec = [] # (zmienne, do których zapisywać będziemy wartości kosztu (dla danych treningowych\n",
    "    loss_val_vec = []   # i walidacyjnych) w kolejnych iteracjach treningu)\n",
    "\n",
    "    # --------------- UZUPEŁNIJ KOD ------------------------------\n",
    "    # Zdefiniuj funkcję kosztu i algorytm optymalizacji\n",
    "    # 1. Niech funkcją kosztu będzie Cross Entropy Loss - zapiszmy ją w obiekcie o nazwie criterion\n",
    "    criterion = 0\n",
    "    # 2. Jako algorytm optymalizacji wybierz Adam ze stałą uczenia lr=0.001 i stałą regularyzacji równą lambdA\n",
    "    #    (zapisz to jako obiekt o nazwie optimizer)\n",
    "    optimizer = 0\n",
    "    # ------------------------------------------------------------\n",
    "    \n",
    "    # Wykonaj 1000 iteracji algorytmu optymalizacji, a przy każdej:\n",
    "    for i in range(1000): \n",
    "        # 1. Oblicz koszt na danych walidacyjnych (aby sprawdzić bias-variance trade-off)\n",
    "        # a) Przełącz model na tryb ewaluacji (tak, by techniki takie jak Dropout czy BatchNorm działały jak trzeba)\n",
    "        if if_plot:\n",
    "            nn.eval()\n",
    "            with torch.no_grad(): # Wyłącz obliczanie gradientów (są potrzebne tylko przy backpropie, tu zapychałyby pamięć)\n",
    "                # b) Forward pass - dokonaj predykcji na danych walidacyjnych\n",
    "                pred = nn(Xval) \n",
    "                # c) Oblicz za pomocą criterion wartość kosztu dla dokonanych predykcji walidacyjnych\n",
    "                loss_val = criterion(pred, yval) \n",
    "                # d) Zapisz wartość kosztu w odpowiedniej zmiennej\n",
    "                loss_val_vec.append(loss_val.detach().numpy())\n",
    "             \n",
    "        # 2. Oblicz koszt na danych treningowych - powtórz podobne kroki, co powyżej:\n",
    "        # --------------- UZUPEŁNIJ KOD -----------------------------------------------------\n",
    "        #  a) Przełącz model na tryb treningu\n",
    "        \n",
    "        # b) Forward pass - dokonaj predykcji na danych treningowych\n",
    "        pred = 0\n",
    "        # c) Oblicz za pomocą criterion wartość kosztu dla dokonanych predykcji treningowych\n",
    "        loss_train = 0\n",
    "        # d) Uruchom na obliczonym koszcie metodę backward(), wykonującą propagację wsteczną błędów (i obliczanie gradientów)\n",
    "         \n",
    "        # e) Wykonaj jedną iterację algorytmu optymalizacji (metoda step() na obiekcie związanym z algorytmem)\n",
    "        \n",
    "        # f) Wyczyść obliczone gradienty, by nie miały wpływu na następne iteracje algorytmu optymalizacji\n",
    "        \n",
    "        # g) Zapisz wartość kosztu w odpowiedniej zmiennej (loss_train_vec)\n",
    "        \n",
    "        # -----------------------------------------------------------------------------------\n",
    "\n",
    "    # Wyświetl krzywe uczenia - zmiany kosztu przy każdej iteracji\n",
    "    if if_plot:\n",
    "        print(\"  Zakończono trening sieci.\")\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(loss_train_vec, color='k')\n",
    "        ax.plot(loss_val_vec, color='r')\n",
    "        ax.set_title(\"Krzywe uczenia\")\n",
    "        ax.set_xlabel(\"Iteracja\")\n",
    "        ax.set_ylabel(\"Koszt\")\n",
    "        ax.legend([\"Koszt na danych treningowych\", \"Koszt na danych walidacyjnych\"])\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy zatem, jak zmieniły się predykcje dokonane przez naszą sieć, kiedy czegoś ją nauczyliśmy (jeszcze bez żadnej regularyzacji): powinniśmy widzieć większe zróżnicowanie wyników."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = train_nn(\n",
    "    Xtrain=Xtrain_norm, \n",
    "    ytrain=ytrain_ohe, \n",
    "    Xval=Xval_norm, \n",
    "    yval=yval_ohe, \n",
    "    num_classes=num_classes,\n",
    "    lambdA=0,\n",
    "    if_plot=False)\n",
    "pred = nn(Xval_norm)\n",
    "print(\"Przykładowe predykcje modelu na danych walidacyjnych (po treningu): \"+str(pred[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predykcja\n",
    "\n",
    "Struktura sieci to jedno, jej trening to drugie, ale ważną rzeczą jest też uporządkowanie sposobu, w jaki rozumiemy predykcje naszej sieci. Przypomnijmy, że każdą z 3 wartości zwracaną przez naszą sieć dla danej próbki powinniśmy utożsamiać z prawdopodobieństwem, że badana próbka danych należy do klasy związanej z danym neuronem. Próbka powinna ostatecznie zostać zaklasyfikowana do tej grupy, której przypisano najwyższe prawdopodobieństwo. Musimy zatem użyć funkcji (proponuję `torch.argmax()`, opisaną [TUTAJ](https://pytorch.org/docs/stable/generated/torch.argmax.html)), która zwraca indeks tej spośród wyjściowych wartości (aktywacji neuronów), która jest największa - w ten sposób otrzymamy numer klasy, do której powinna należeć nasza badana próbka. <font size=\"2\">Jest to niejako operacja odwrotna do one-hot-encodingu.</font>\n",
    "\n",
    "Uzupełnij zatem kod funkcji `pred_nn()`, która zawiera implementację powyższych działań."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_nn(X, nn):\n",
    "    \"\"\"\n",
    "    Dokonuje ostatecznej predykcji sieci neuronowej (obiektu NeuralNet) - wskazania klasy - dla danych wejściowych X. \\n\n",
    "    Argumenty: \\n\n",
    "    - X - dane wejściowe (torch tensor, shape = (num_samples, num_features) ), \\n\n",
    "    - nn - model sieci neuronowej, obiekt naszej klasy NeuralNet\n",
    "    Zwraca: pred - numer klasy wg klasyfikatora właściwy dla X (numpy array, shape = (num_samples,) ).\n",
    "    \"\"\"\n",
    "    # --------- UZUPEŁNIJ KOD -------------\n",
    "    pred = 0\n",
    "    # -------------------------------------\n",
    "    return pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zobaczmy, jak wyglądają nasze predykcje dla danych walidacyjnych, kiedy jednoznacznie wskazujemy, do której klasy przypisać daną próbkę (a nie operujemy na prawdopodobieństwach):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred_nn(Xval_norm, nn)\n",
    "print(\"Przykładowe predykcje dla danych walidacyjnych: \"+str(pred[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dobór hiperparametrów\n",
    "\n",
    "W ostatnim kroku postarajmy się znaleźć taką wartość stałej regularyzacji $\\lambda$, przy której nasz model działa najlepiej - to znaczy, osiąga najwyższą dokładność na danych, których wcześniej nie widział (walidacyjnych). $\\lambda$ odpowiada za to, jak bardzo model ,,karany'' jest za budowanie skomplikowanych hipotez. Będziemy szukać odpowiedniej wartości $\\lambda$ wśród następujących: 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5 oraz 1.\n",
    "\n",
    "Napiszmy funkcję `choose_lambda`, której główna część powinna składać się z następujących kroków:\n",
    "* Sprawdzenie działania modelu dla każdej z badanych wawrtości $\\lambda$:\n",
    "    * Dokonaj treningu (na danych treningowych) sieci z zadaną wartością $\\lambda$.\n",
    "    * Dokonaj klasyfikacji tych danych i oblicz jej skuteczność (dokładność).\n",
    "    Wskazówka: Aby zmierzyć skuteczność, musimy mieć możliwość łatwego porówania predykcji i etykiet *ground truth*, a zwróć uwagę, że tutaj przekazujemy do funkcji jako argument rtykiety już przekształcone przez one-hot-encoding, aby mogły posłużyć do treningu sieci. W celu odwrócenia one-hot-encodingu, zastosuj przykładowo funkcję `np.where` ([TUTAJ](https://numpy.org/doc/stable/reference/generated/numpy.where.html)). \n",
    "    * Dokonaj klasyfikacji danych walidacyjnych i oblicz jej dokładność.\n",
    "* Wyświetl, jak zmieniała się dokładność klasyfikacji na obu zestawach danych w zależności od użytej wartości $\\lambda$.\n",
    "* Wybierz tę wartość $\\lambda$, przy której model osiągnął najwyższą dokładność na danych z zestawu walidacyjnego - tutaj znów przyjdzie nam z pomocą funkcja `np.argmax`, tym razem z biblioteki NumPy ([TUTAJ](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_lambda(Xtrain, ytrain, Xval, yval, num_classes):\n",
    "    \"\"\"\n",
    "    Znajdź wartość optymalnej stałej regularyzacji lambda dla sieci neuronowej klasy NeuralNet. \\n\n",
    "    Argumenty: \\n\n",
    "    - Xtrain - dane treningowe (torch tensor, shape = (num_samples * percentage_train, num_features) ), \\n\n",
    "    - ytrain - etykiety do danych treningowych po one-hot-encodingu\n",
    "        (torch tensor, shape = (num_samples * percentage_train, num_classes) ), \\n\n",
    "    - Xval - dane walidacyjne (torch tensor, shape = (num_samples * percentage_val, num_features) ), \\n\n",
    "    - yval - etykiety do danych walidacyjnych po one-hot-encodingu\n",
    "        (torch tensor, shape = (num_samples * percentage_val, num_classes) ), \\n\n",
    "    - num_classes - ilość klas, tj. ile różnych wartości pojawia się w etykietach (int, skalar). \\n\n",
    "    Zwraca: optimal_lambda - optymalna wartość stałej regularyzacji dla Twojej sieci (float, skalar).\n",
    "    \"\"\"\n",
    "    lambdas = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1]\n",
    "    accuracies_train = []\n",
    "    accuracies_val = []\n",
    "    # ------- UZUPEŁNIJ KOD ------------------------------------------------------------------\n",
    "    for lambdA in lambdas:\n",
    "        # 1. Wykonaj trening sieci neuronowej z wartością lambda z tej iteracji \n",
    "        # (z wykorzystaniem train_nn, tak, by nie wyświetlały się stałe uczenia)\n",
    "        nn = 0\n",
    "        # 2. Forward pass - oblicz predykcje sieci dla danych treningowych (z wykorzystaniem pred_nn)\n",
    "        pred_train = 0\n",
    "        # 3. Odwróć one-hot-endocing etykiet treningowych (do obliczenia dokładności)\n",
    "        ytrain_original = 0\n",
    "        # 4. Oblicz dokładność sieci na danych treningowych (tj. średnia ilość decyzji dobrze podjętych przez sieć)\n",
    "        accuracy_train = 0\n",
    "        # 5. Dodaj obliczoną chwilę temu wartość dokładności do listy accuracies_train (metodą .append() )\n",
    "        \n",
    "        # Powtórz kroki 1-5 dla danych walidacyjnych\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Wybierz optymalną wartość lambda - tę, przy której mamy najwyższą dokładność \n",
    "    # na zestawie walidacyjnym (podpowiedź: wykorzystaj metodę np.argmax)\n",
    "    optimal_lambda =0 \n",
    "    # -----------------------------------------------------------------------------------------\n",
    "    \n",
    "    print(\"Optymalna wartość lambda: \" + str(optimal_lambda))\n",
    "    # Wyświetl zależność dokładności od lambda dla obu zestawów\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(lambdas, accuracies_train, color='k')\n",
    "    ax.plot(lambdas, accuracies_val, color='r')\n",
    "    ax.set_title(\"Wpływ lambda na działanie sieci\")\n",
    "    ax.set_xlabel(\"Lambda\")\n",
    "    ax.set_ylabel(\"Dokładność\")\n",
    "    ax.legend([\"Dokładność na danych treningowych\", \"Dokładność na danych walidacyjnych\"])\n",
    "    return optimal_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czas uruchomić całość, łącznie z poszukiwaniem optymalnej wartości $\\lambda$! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Trening sieci neuronowej -------------------------\n",
    "# Dobierz wartość hiperparametru lambda (do regularyzacji)\n",
    "optimal_lambda = choose_lambda(\n",
    "    Xtrain=Xtrain_norm, \n",
    "    ytrain=ytrain_ohe, \n",
    "    Xval=Xval_norm, \n",
    "    yval=yval_ohe, \n",
    "    num_classes=num_classes)\n",
    "# Dokonaj ostatecznego treningu sieci neuronowej\n",
    "nn = train_nn(\n",
    "    Xtrain=Xtrain_norm, \n",
    "    ytrain=ytrain_ohe, \n",
    "    Xval=Xval_norm, \n",
    "    yval=yval_ohe, \n",
    "    num_classes=num_classes,\n",
    "    lambdA=optimal_lambda)\n",
    "\n",
    "# ----------------- Predykcja i sprawdzenie działania -------------------\n",
    "pred = pred_nn(Xtrain_norm, nn)\n",
    "accuracy = np.mean(pred==ytrain)\n",
    "print(\"Dokładność modelu na danych treningowych: \"+str(accuracy*100)+'%')\n",
    "pred = pred_nn(Xval_norm, nn)\n",
    "accuracy = np.mean(pred==yval)\n",
    "print(\"Dokładność modelu na danych walidacyjnych: \"+str(accuracy*100)+'%')\n",
    "pred = pred_nn(Xtest_norm, nn)\n",
    "accuracy = np.mean(pred==ytest)\n",
    "print(\"Dokładność modelu na danych testowych: \"+str(accuracy*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli na wykresie krzywych uczenia nie obserwujesz znaczącego *overfittingu* (krzywa dla zestawu walidacyjnego nie rośnie przy dalszym spadku krzywej dla zestawu treningowego) - świetnie! Udało Ci się wytrenować sieć neuronową.\n",
    "\n",
    "## 4.2 Dowolny tuning sieci\n",
    "\n",
    "Czas na Twoją inwencję! W naszej sieci mamy jeszcze kilka innych hiperparametrów oprócz $\\lambda$. Spróbuj pozmieniać wartości:\n",
    "* prawdopodobieństwa ,,wypadnięcia'' neuronu na warstwie *Dropout*,\n",
    "* ilości iteracji algorytmu optymalizacji,\n",
    "* ilości neuronów na warstwie ukrytej,\n",
    "* a może nawet ilości warstw (może samodzielnie dodasz kolejną?).\n",
    "\n",
    "Dokonaj modyfikacji w kodzie, po czym ponownie uruchom poszczególne komórki, by sprawdzić, jak zmieniła się skuteczność działania Twojej sieci neuronowej.\n",
    "\n",
    "\n",
    "## 4.3 Implementacja prostej sieci neuronowej ,,od zera''\n",
    "\n",
    "Przekonaliśmy się, że PyTorch (oraz inne podobne biblioteki) umożliwia nam zbudowanie sieci neuronowej, korzystając z predefiniowanych, gotowych ,,bloczków''. Żeby jednak dokładniej zrozumieć ideę przekazywania danych pomiędzy warstwami oraz sposób działania propagacji wstecznej, warto zbudować sieć samemu.\n",
    "\n",
    "Wykorzystamy te same dane, które pobraliśmy w celu wykonania wcześniejszych podpunktów - tutaj jedynie nie będziemy musieli przekształcać ich na tensory, gdyż operować będziemy z wykorzystaniem jedynie biblioteki NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Inicjalizacja ----------------------------\n",
    "# Wczytanie danych\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "num_classes = (np.unique(y)).shape[0]\n",
    "# Podziel dane na zestaw treningowy (70%), walidacyjny (15%) i testowy (15%) z wykorzystaniem metody train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,train_size=0.7)\n",
    "Xval, Xtest, yval, ytest = train_test_split(Xtest,ytest,train_size=0.5)\n",
    "# Dokonaj standaryzacji danych z wykorzystaniem klasy StandardScaler\n",
    "scaler = StandardScaler()\n",
    "Xtrain_norm = scaler.fit_transform(Xtrain)\n",
    "Xval_norm = scaler.fit_transform(Xval)\n",
    "Xtest_norm = scaler.fit_transform(Xtest)\n",
    "# Dokonaj one-hot-encodingu etykiet z zestawu treningowego i walidacyjnego\n",
    "ytrain_ohe = np.identity(num_classes)[ytrain]\n",
    "yval_ohe = np.identity(num_classes)[yval]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przyjrzyj się, jak w funkcji `pred_raw_nn` zaimplementowano *forward pass* naszej sieci. Tym razem, dla uproszczenia, nasza sieć niech składa się również z trzech warstw, ale jako funkcję aktywacji wykorzystajmy znaną nam już funkcję sigmoid ($f(z)=\\frac{1}{1+\\exp(-z)}$), a jako jedyny sposób walki z przeuczeniem niech posłuży nam regularyzacja (nie będziemy tu implementować *dropout*u). Nasza funkcja, oprócz zwrócenia konkretnych etykiet przypisanych do badanych danych przez model, zwraca również wawrtości pośrednie (aproksymacje $z$ i aktywacje $a$) występujące podczas ,,wędrówki'' danych poprzez naszą sieć (zwróć uwagę, że zapisane są one w postaci listy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_raw_nn(X, Theta):\n",
    "    \"\"\"\n",
    "    Dokonuje ostatecznej predykcji naszej sieci neuronowej - wskazania klasy - dla danych wejściowych X\n",
    "    i sieci neuronowej (Linear + Sigmoid)->(Linear + Sigmoid). \\n\n",
    "    Argumenty: \\n\n",
    "    - X - dane wejściowe (torch tensor, shape = (num_samples, num_features) ), \\n\n",
    "    - Theta - lista zawierająca wyuczone macierze wag sieci neuronowej w postaci numpy array, \n",
    "        shape = (in_layer_size, out_layer_size)). \\n\n",
    "    Zwraca: \\n\n",
    "    - pred - numer klasy wg klasyfikatora właściwy dla X (numpy array, shape = (num_samples,) ), \\n\n",
    "    - a - lista zawierająca wektory aktywacji dla warstw sieci oprócz wejściowej \n",
    "        (numpy arrays, shape = (num_samples, layer_size))\n",
    "    - z - lista zawierająca wektory aproksymacji (przez użyciem funkcji aktywacji) dla warstw sieci oprócz wejściowej \n",
    "        (numpy arrays, shape = (num_samples, layer_size))    \n",
    "    \"\"\"\n",
    "    # Forward pass\n",
    "    z1 = np.dot(X,Theta[0]) # Linear\n",
    "    a1 = 1/(1+np.exp(-z1)) # Sigmoid\n",
    "    z2 = np.dot(a1,Theta[1]) # Linear\n",
    "    a2 = 1/(1+np.exp(-z2)) # Sigmoid\n",
    "    a = [a1, a2]\n",
    "    z = [z1, z2]\n",
    "    # Predykcja\n",
    "    pred = np.argmax(a2, axis=1)\n",
    "    return pred, a, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pora na nieco Twojej pracy! Uzupełnij poniższy kod funkcji `compute_cost_and_gradient_nn()`. \n",
    "* Jako koszt, zaimplementuj Cross Entropy Loss dla przypadku wieloklasowego z regularyzacją: \n",
    "\\begin{equation*}\n",
    "J(\\Theta) = \\frac{1}{m} (\\sum_{c=1}^{\\textrm{num\\_classes}} [-y_c \\cdot \\log(h_c(x)) - (1-y_c) \\cdot \\log(1-h_c(x))] + \n",
    "\\lambda \\cdot [||\\Theta^{(1)}||_2 + ||\\Theta^{(2)}||_2] )\n",
    "\\end{equation*}\n",
    "gdzie:\n",
    "    * $m$ to ilość próbek w batchu,\n",
    "    * $y_c$ to `y[:,c]` (jeśli punkt należy do klasy $c$, to $y_c=1$),\n",
    "    * $h_c(x)$ to w naszym przypadku $a^{(2)}_c$ (aktywacja neuronu wyjściowego odpowiedzialnego za klasę $c$),\n",
    "    * możesz użyć sztuczki: $||\\Theta^{(l)}||_2 = \\Theta^{(l)}[:,:] \\cdot \\Theta^{(l)}[:,:]^T $ (przydadzą się funkcje `np.transpose` i `np.dot`, a także  `np.ravel()`([TUTAJ](https://numpy.org/doc/stable/reference/generated/numpy.ravel.html)) ).\n",
    "\n",
    "* Do implementacji propagacji wstecznej, użyj nieco zmodyfikowanych wzorów z rysunku z rodziału 1 (uwzględniających ,,zgranie'' wymiarów mnożonych macierzy oraz składnik regularyzacji):\n",
    "    * $\\delta^{(2)} = a^{2} - y$,\n",
    "    * $ \\frac{\\partial J(\\Theta)}{\\partial \\Theta^{(2)}} = \\frac{1}{m} (a^{(1)T} \\cdot \\delta^{(2)} + \\lambda \\Theta^{(2)}) $,\n",
    "    * $ \\delta^{(1)} = \\delta^{(2)} \\cdot \\Theta^{(2)T} * (\\textrm{sigmoid}(z^{(1)}))(1-\\textrm{sigmoid}(z^{(1)})) $ (bo dla $f(z)=\\textrm{sigmoid}(z)$, $f'(z) = f(z)(1-f(z))$),\n",
    "    * $ \\frac{\\partial J(\\Theta)}{\\partial \\Theta^{(1)}} = \\frac{1}{m} (X^T \\cdot \\delta^{(1)} + \\lambda \\Theta^{(1)}) $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_and_gradient_nn(X, y, Theta):\n",
    "    \"\"\"\n",
    "    Funkcja zwracająca koszt (Cross Entropy Loss) i gradienty naszej sieci neuronowej o budowie\n",
    "    (Linear + Sigmoid)->(Linear + Sigmoid). \\n\n",
    "    Argumenty: \\n\n",
    "    - X - dane wejściowe (numpy array, shape = (num_samples, num_features) ), \\n\n",
    "    - y - etykiety do danych po one-hot-encodingu (numpy array, shape = (num_samples, num_classes) ), \\n\n",
    "    - Theta - lista zawierająca wyuczone macierze wag sieci neuronowej w postaci numpy array, \n",
    "        shape = (in_layer_size, out_layer_size)).\\n\n",
    "    Zwraca: \\n\n",
    "    - J - obliczony koszt Cross Entropy (skalar, float), \\n\n",
    "    - grad - lista zawierająca gradienty macierzy wag sieci neuronowej w postaci numpy array, \n",
    "        shape = (in_layer_size, out_layer_size)).\n",
    "    \"\"\"\n",
    "    lambdA = 0.1 # regularization term\n",
    "    Theta1 = Theta[0]\n",
    "    Theta2 = Theta[1]\n",
    "    _, a, z = pred_raw_nn(X, Theta)\n",
    "    a1 = a[0]\n",
    "    a2 = a[1]\n",
    "    z1 = z[0]\n",
    "    # Oblicz koszt\n",
    "    J = 0\n",
    "    # -------------------------- UZUPEŁNIJ KOD ----------------------\n",
    "    for c in range(y.shape[1]): \n",
    "        # a) Oblicz BCE dla każdej klasy z osobna\n",
    "        J = 0\n",
    "    # b) Dodaj regularyzację\n",
    "    J = 0\n",
    "    # Zaimplementuj backprop - oblicz błędy warstw i gradienty maccierzy wag\n",
    "    # a) Błąd warstwy wyjściowej - d2\n",
    "    d2 = 0\n",
    "    # b) Gradient drugiej macierzy wag - grad2\n",
    "    grad2 = 0\n",
    "    # c) Błąd warstwy ukrytej - d1\n",
    "    d1 = 0\n",
    "    # d) Gradient pierwszej macierzy wag - grad1\n",
    "    grad1 = 0\n",
    "    # --------------------------------------------------------------\n",
    "    grad = [grad1, grad2]\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Napisałam za Ciebie funkcję `train_raw_nn`, która będzie zawierać niejako połączenie tego, co udało się zrobić na poprzednich zajęciach (funkcja `train_logistic_regression()`) i tego, co robiliśmy dzisiaj (funkcja `train_nn()`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_raw_nn(Xtrain, ytrain, Xval, yval, num_classes):\n",
    "    \"\"\"\n",
    "    Wykonaj trening swojej sieci neuronowej o budowie (Linear + Sigmoid)->(Linear + Sigmoid)\n",
    "    na zadanych danych wejściowych i z określoną stałą regularyzacji lambda. \\n\n",
    "    Argumenty:\n",
    "    - Xtrain - dane treningowe (numpy array, shape = (num_samples * percentage_train, num_features) ), \\n\n",
    "    - ytrain - etykiety do danych treningowych po one-hot-encodingu\n",
    "        (numpy array, shape = (num_samples * percentage_train, num_classes) ), \\n\n",
    "    - Xval - dane walidacyjne (numpy array, shape = (num_samples * percentage_val, num_features) ), \\n\n",
    "    - yval - etykiety do danych walidacyjnych po one-hot-encodingu\n",
    "        (numpy array, shape = (num_samples * percentage_val, num_classes) ), \\n\n",
    "    - num_classes - ilość klas, tj. ile różnych wartości pojawia się w etykietach (int, skalar). \\n\n",
    "    Zwraca: Theta - lista zawierająca wyuczone macierze wag sieci neuronowej \n",
    "        w postaci numpy array, shape = (in_layer_size, out_layer_size)).\n",
    "    \"\"\"\n",
    "    hidden_layer_size = 8\n",
    "    alpha = 0.05 # learning rate\n",
    "    num_iterations = 1000\n",
    "    Theta1 = 2 * np.random.random(size=(Xtrain.shape[1], hidden_layer_size)) - 1\n",
    "    Theta2 = 2 * np.random.random(size=(hidden_layer_size, num_classes)) - 1\n",
    "    Theta = [Theta1, Theta2]\n",
    "    loss_train_vec = np.zeros((num_iterations)) \n",
    "    loss_val_vec = np.zeros((num_iterations))\n",
    "\n",
    "    for i in range(num_iterations): \n",
    "        # Oblicz wartość kosztu i gradienty\n",
    "        J_train, grad = compute_cost_and_gradient_nn(Xtrain, ytrain, Theta)\n",
    "        J_val, _ = compute_cost_and_gradient_nn(Xval, yval, Theta)\n",
    "        # Dokonaj aktualizacji wag\n",
    "        for j in range(len(Theta)): Theta[j] = Theta[j]-alpha*grad[j] \n",
    "        # Zapisz wartość kosztu w odpowiednich zmiennych\n",
    "        loss_train_vec[i] = J_train\n",
    "        loss_val_vec[i] = J_val\n",
    "\n",
    "    # Wyświetl krzywe uczenia - zmiany kosztu przy każdej iteracji\n",
    "    print(\"  Zakończono trening sieci.\")\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(loss_train_vec, color='k')\n",
    "    ax.plot(loss_val_vec, color='r')\n",
    "    ax.set_title(\"Krzywe uczenia\")\n",
    "    ax.set_xlabel(\"Iteracja\")\n",
    "    ax.set_ylabel(\"Koszt\")\n",
    "    ax.legend([\"Koszt na danych treningowych\", \"Koszt na danych walidacyjnych\"])\n",
    "    return Theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nic nie stoi zatem na przeszkodzie, by spróbować uruchomić naszą sieć neuronową!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Trening sieci neuronowej -------------------------\n",
    "# Dokonaj treningu sieci neuronowej\n",
    "Theta = train_raw_nn(\n",
    "    Xtrain=Xtrain_norm, \n",
    "    ytrain=ytrain_ohe, \n",
    "    Xval=Xval_norm, \n",
    "    yval=yval_ohe, \n",
    "    num_classes=num_classes)\n",
    "\n",
    "# ----------------- Predykcja i sprawdzenie działania -------------------\n",
    "pred, _, _ = pred_raw_nn(Xtrain_norm, Theta)\n",
    "accuracy = np.mean(pred==ytrain)\n",
    "print(\"Dokładność modelu na danych treningowych: \"+str(accuracy*100)+'%')\n",
    "pred, _, _ = pred_raw_nn(Xval_norm, Theta)\n",
    "accuracy = np.mean(pred==yval)\n",
    "print(\"Dokładność modelu na danych walidacyjnych: \"+str(accuracy*100)+'%')\n",
    "pred, _, _ = pred_raw_nn(Xtest_norm, Theta)\n",
    "accuracy = np.mean(pred==ytest)\n",
    "print(\"Dokładność modelu na danych testowych: \"+str(accuracy*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oczywiście, jeśli wyniki Cię nie satysfakcjonują, spróbuj ręcznie pozmieniać niektóre parametry sieci.\n",
    "\n",
    "\n",
    "## 5. Pytania kontrolne\n",
    "1. Jaka jest rola funkcji aktywacji na każdej warstwie sieci neuronowej?\n",
    "2. Opisz krótko, na czym polega propagacja wsteczna (w odniesieniu do treningu sieci neuronowej).\n",
    "3. Czym jest przeuczenie modelu? Wymień znane Ci techniki, które mu przeciwdziałają."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
